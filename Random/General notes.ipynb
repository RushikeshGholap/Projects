{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Lecture 1 Inside Bloomberg, Foundations of ML, YT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series test train split\n",
    " \n",
    " Fix a date and every thing after that date becomes test. Never work with relative/rolling windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Fold Cross Validation\n",
    "\n",
    "The intent is NOT to evaluate a prediction function, but actually evaluate the average performance of a model building procedure.\n",
    "\n",
    "1. Make k partitions of the data\n",
    "2. Put each k partition in the holdout set and remaining data as training set.\n",
    "3. Train the same model on each of the training sets (k) and test it against the holdout set respectively.\n",
    "4. Analyze the mean of the predictions and std.deviation ($\\sigma / \\sqrt{k}$)\n",
    "5. Tune the model till you are sure that you are not overfitting\n",
    "6. Train the model with exact same parameters on complete data\n",
    "\n",
    "The accuracy of this model will be atleast as good as the lowest accuracy achieved by the k models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leakage\n",
    "\n",
    "Sometimes info from the labels is leaked into some of the features. eg. Using the star rating along with text info to predict sentiment. The sentiment has 'leaked' into the rating which is wrong if you are trying to build a pure text classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Bias\n",
    "\n",
    "When selection of data used during test is not a good representation of the deployment data (similar thing can be said between training and test samples). eg. creating a mode to predict US voting patterns but using data from only landline phone surveys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "A learning algorithm calculates the parameters estimates using the inputs and outputs, which are in the form of weights and biases. But, the learning algorithm itself has some parameters which are called hyperparameters (such as k in KNN, num_trees in Decision trees). They can control various things such as -\n",
    "\n",
    "- model complexity\n",
    "- type of model complexity control (l1 vs l2)\n",
    "- optimization algorithm and learning rate\n",
    "- model type (loss function, kernel type etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model complexity\n",
    "\n",
    "Larger model complexity means high fit to training data, but not necessarily the test data. Its controlled usually by the model hyperparameters, type of model or model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What to do with overfitting\n",
    "\n",
    "1. Reduce model complexity\n",
    "2. Get more training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Theory - Formalization\n",
    "\n",
    "Any problem can be formalized by -\n",
    "\n",
    "- Defining an action space (set of possible actions, eg. null hyp = True/False, prediction = 1,2,3)\n",
    "- Specify evaluation criteria to measure success or faliure of the prolem\n",
    "\n",
    "We also have some other information such as - \n",
    "\n",
    "- inputs (input data, sequence, covariate (statistics about the problem), search query)\n",
    "- output, outcome, label (what actually happened)\n",
    "\n",
    "SO:\n",
    "\n",
    "1. Observe input x\n",
    "2. Take action a\n",
    "3. Observe outcome y\n",
    "4. Evaluate action a using loss(y,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
