{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.random((3*100))\n",
    "out = np.argmin(n.reshape((-1,3)), axis=1)\n",
    "\n",
    "print(n.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dfs = [i[1] for i in df.groupby(\"Symbols\")]\n",
    "\n",
    "for i in grouped_dfs:\n",
    "    print(i)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "N_samples = int(1e4)\n",
    "N_nan = N_var = int(0.02 * N_samples)\n",
    "\n",
    "# Generate random data\n",
    "data = np.random.rand(N_samples,2) * [30, 360]\n",
    "data[np.random.choice(N_samples, N_nan), 1] = np.nan\n",
    "data[np.random.choice(N_samples, N_var), 1] = 990\n",
    "\n",
    "# Create dataset\n",
    "df = pd.DataFrame(data, columns=['WindSpeed', 'WindDir'])\n",
    "df.index = pd.date_range(start='2000-01-01 00:00', periods=N_samples, freq='10min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meandir(x):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pandas.Series\n",
    "        pandas series to be averaged\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        averaged wind direction\n",
    "    '''\n",
    "\n",
    "    # Removes the NaN from the recording\n",
    "    x = x.dropna()\n",
    "\n",
    "    # If the record is empty, return NaN\n",
    "    if len(x)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # If the record contains variable samples (990) return variable (990)\n",
    "    elif np.any(x == 990):\n",
    "        return 990\n",
    "\n",
    "    # Otherwise sum the vectors and return the angle\n",
    "    else:\n",
    "        angle = np.rad2deg(\n",
    "                           np.arctan2(\n",
    "                                   np.sum(np.sin(np.deg2rad(x))),\n",
    "                                   np.sum(np.cos(np.deg2rad(x)))\n",
    "                                     )\n",
    "                          )\n",
    "\n",
    "        #Wrap angles from (-pi,pi) to (0,360)\n",
    "        return (angle + 360) % 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(pd.Grouper(freq='H'))   # Data from 14.30 to 15.29 are rounded to 15.00\n",
    "aggfuns1 = {'WindSpeed': np.mean, 'WindDir':meandir}\n",
    "aggfuns2 = {'WindSpeed': np.mean, 'WindDir':np.mean}\n",
    "\n",
    "res = repeat(stmt='grouped.agg(aggfuns1)', globals=globals(), number=1, repeat=10)\n",
    "print(f'With custom aggregating function {min(res)*1000:.2f} ms')\n",
    "\n",
    "res = repeat(stmt='grouped.agg(aggfuns2)', globals=globals(), number=1, repeat=10)\n",
    "print(f'Without custom aggregating function {min(res)*1000:.2f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([i[1].shape for i in df.dropna().groupby(pd.Grouper(freq='H'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Grouper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(aggfuns1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# original data\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y = [2, 7, 3, 4, 5, 1, 6, 9, 4, 6]\n",
    "\n",
    "# quadratic regression\n",
    "for i in range(int((len(x) + len(y)) / 2)):\n",
    "    sub_x = x[i:i+3]\n",
    "    sub_y = y[i:i+3]\n",
    "    \n",
    "    model = np.poly1d(np.polyfit(sub_x, sub_y, 2))\n",
    "    polyline = np.linspace(min(sub_x), max(sub_x), 200)\n",
    "    plt.plot(polyline, model(polyline), color=\"#6D34D6\", linestyle='dashed')\n",
    "\n",
    "\n",
    "#Interpolate\n",
    "x_new = np.linspace(min(x), max(x), 300)  \n",
    "f = interp1d(x, y, kind='quadratic')\n",
    "\n",
    "# plot lines\n",
    "plt.scatter(x, y, color='#FF3FAF')\n",
    "plt.plot(x_new,f(x_new), color='#FF3FAF', linestyle='solid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = np.random.random((25, 1010, 7, 512))\n",
    "b = np.random.random((10, 7))\n",
    "\n",
    "A = tf.convert_to_tensor(a)\n",
    "B = tf.convert_to_tensor(b)\n",
    "\n",
    "out = tf.concat([A[:,:10,:,:] + B[None, :, :, None], A[:,10:,:,:]], axis=1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A[:,:10,:,:] + B[None, :, :, None]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,:10,:,:] += b[None,:,:,None]\n",
    "\n",
    "tf.reduce_all(tf.convert_to_tensor(a) == out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "M, N = 1001, 1001\n",
    "u = 100\n",
    "v = 200\n",
    "sin_img = np.zeros((M, N))\n",
    "for m in range(M):\n",
    "    for n in range(N):\n",
    "        sin_img[m, n] = np.sin((2 * np.pi * u * m / M) + (2 * np.pi * v * n / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "idx_sin_img = np.stack(np.indices((M,N)), axis=-1) #(1001,1001,2)\n",
    "out = np.sin((2 * np.pi * u * idx_sin_img[...,0] / M) + \n",
    "             (2 * np.pi * v * idx_sin_img[...,1] / N))\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "sin_img = np.array([[np.sin((2 * np.pi * u * m / M) + (2 * np.pi * v * n / N))\n",
    "    for n in range(N)]\n",
    "    for m in range(M)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin((2 * np.pi * u * m / M) + (2 * np.pi * v * n / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_img = np.zeros((M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5,3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strides = (a.strides[0], a.strides[1]*2, a.strides[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.lib.stride_tricks.as_strided(a, shape, strides)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2, 3,4, 2,5],  \n",
    "[1,2, 2,5, 3,4],  \n",
    "[3,4, 1,2, 2,5],  \n",
    "[3,4, 2,5, 1,2],  \n",
    "[2,5, 1,2, 3,4], and \n",
    "[2,5, 3,4, 1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2,  3,4,  2,5], \n",
    "              [4,5,  6,7,  8,9],\n",
    "              [2,5,  1,3,  2,5],\n",
    "              [0,4,  0,4,  0,4],\n",
    "              [0,3,  1,7,  2,4]])\n",
    "\n",
    "b = a[:,[4,5,2,3,0,1]]\n",
    "\n",
    "np.hstack([a,\n",
    "           np.roll(b, 2, axis=1),\n",
    "           np.roll(b, 4, axis=1),           \n",
    "           np.roll(a, 4, axis=1),\n",
    "           np.roll(a, 2, axis=1),  \n",
    "           b]).reshape(5,-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_clipboard('\\s\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['properties'].apply(lambda x: [(k,v) for k,v in x.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [ \"a\", \n",
    "          \"b\", \n",
    "          \"c\" ]\n",
    "list2 = [ \"e\", \n",
    "          \"f\",\n",
    "          \"g\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    [2 * x  if x > 1 else 0 for x in [1,2,3]]\n",
    "except SyntaxError:\n",
    "    print(\"Why isn't this printed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eval(\"[2 * x for x in [1,2,3] if x > 1 else 0]\") #<----\n",
    "except SyntaxError:\n",
    "    print(\"Why isn't this printed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_path(Z):\n",
    "    start = (1,1)\n",
    "    goal = (-2,-2)\n",
    "    \n",
    "    G = np.zeros(Z.shape)\n",
    "    G_gamma = np.zeros(G.shape)\n",
    "    G[start] = 1000\n",
    "    \n",
    "    break_counter = 0\n",
    "    longest_possible_path = np.max(Z.shape)*(int(np.min(Z.shape)/2)+1)+(int(np.min(Z.shape)/2)+1)\n",
    "    \n",
    "    while G[goal] == 0 and break_counter<longest_possible_path:\n",
    "        break_counter+=1\n",
    "        G_gamma = np.subtract(G, 1)\n",
    "        N = G_gamma[0:-2,1:-1]\n",
    "        W = G_gamma[1:-1,0:-2]\n",
    "        C = G[1:-1,1:-1]\n",
    "        E = G_gamma[1:-1,2:]\n",
    "        S = G_gamma[2:,1:-1]\n",
    "        G[1:-1,1:-1] = Z[1:-1,1:-1]*np.maximum.reduce([N,S,E,W,C])\n",
    "    \n",
    "    if G[goal] != 0:\n",
    "        num_steps = int(1000 - G[goal] + 1)\n",
    "    else:\n",
    "        num_steps = Z.shape[0]*Z.shape[1]\n",
    "    return num_steps\n",
    "\n",
    "def solution(map):\n",
    "    maze = (np.pad(map, 1, mode='constant', constant_values=1)==0).astype(int)\n",
    "    best_run = get_path(maze)\n",
    "    walls = np.argwhere(map)+1\n",
    "\n",
    "    for i in walls:\n",
    "        maze[tuple(i)]=1\n",
    "        p = get_path(maze)\n",
    "        if p<best_run:\n",
    "            best_run=p\n",
    "        maze[tuple(i)]=0\n",
    "    \n",
    "    return best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(9)\n",
    "print([i for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3], \n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d1 = np.diag(np.array(a))\n",
    "d2 = np.diag(np.flip(np.array(a), axis=1))\n",
    "\n",
    "print(d1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [a[i][i] for i in range(len(a))]\n",
    "d2 = [a[i][j] for i,j in enumerate(reversed(range(len(a[0]))))]\n",
    "print(d1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = []\n",
    "d2 = []\n",
    "\n",
    "for i,j in enumerate(reversed(range(len(a[0])))):\n",
    "    d1.append(a[i][i])\n",
    "    d2.append(a[i][j])\n",
    "    \n",
    "print(d1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2\n",
    "stop = 11\n",
    "factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(int(2*10), int(11*10), int(0.1*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(0.1*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [i for i in range(2,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listt =[[' 2020-06-12  00:00:00+03:00 ',' 91.5','91.9','91.9','91.9','92.55','92.55','92.1','93.3','93.3 '],\n",
    "    [' 2020-06-13  00:00:00+03:00 ',' 91.6','91.6','92.85','92.85','92.85','92.85','92.3','92.3','92.1','92.1','94.1',],\n",
    "    [' 2020-06-14  00:00:00+03:00 ',' 91.5','91.5','91.65','91.65','91.5','92.9','92.9 '],\n",
    "    [' 2020-06-15  00:00:00+03:00 ',' 91.85','91.85','91.6','91.85','91.85','92.55','92.4','92.4','93.7','93.7','93.35','93.35 '],\n",
    "    [' 2020-06-16  00:00:00+03:00 ',' 91.6','91.6','91.3','91.3','92.75','92.75','92.15','92.15','93.15','93.15','92.9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([(i[0],len(i)-2) for i in listt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 5,max_depth=2, random_state=0, verbose=2)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.estimators_[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib_rec(n):\n",
    "    if n == 1:\n",
    "        return [0]\n",
    "    elif n == 2:\n",
    "        return [0,1]\n",
    "    else:\n",
    "        x = fib_rec(n-1)\n",
    "        # the new element the sum of the last two elements\n",
    "        x.append(sum(x[:-3:-1]))\n",
    "        return x\n",
    "\n",
    "    \n",
    "data = fib_rec(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary classification\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "import tensorflow as tf\n",
    "\n",
    "y_true = [0,1,1,1]\n",
    "y_pred = [1,0,1,1]\n",
    "\n",
    "print('sklearn precision: ',precision_score(y_true, y_pred, average='binary'))\n",
    "#Only report results for the class specified by pos_label. \n",
    "#This is applicable only if targets (y_{true,pred}) are binary.\n",
    "\n",
    "m.reset_states()\n",
    "m = tf.keras.metrics.Precision()\n",
    "m.update_state(y_true, y_pred)\n",
    "print('tf.keras precision:',m.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Multi-class classification (global precision)\n",
    "\n",
    "y_true = [[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]]\n",
    "y_pred = [[1,0,0],[0,0,1],[0,1,0],[1,0,0],[1,0,0],[0,1,0]]\n",
    "\n",
    "print('sklearn precision: ',precision_score(y_true, y_pred, average='micro'))\n",
    "#If None, the scores for each class are returned.\n",
    "\n",
    "m.reset_states()\n",
    "m = tf.keras.metrics.Precision()\n",
    "m.update_state(y_true, y_pred)\n",
    "print('tf.keras precision:',m.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-class classification (binary precision for each label)\n",
    "\n",
    "y_true = [[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]]\n",
    "y_pred = [[1,0,0],[0,0,1],[0,1,0],[1,0,0],[1,0,0],[0,1,0]]\n",
    "\n",
    "print('sklearn precision: ',precision_score(y_true, y_pred, average=None))\n",
    "#Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    "#For class 0\n",
    "m0 = tf.keras.metrics.Precision(class_id=0)\n",
    "m0.update_state(y_true, y_pred)\n",
    "\n",
    "#For class 1\n",
    "m1 = tf.keras.metrics.Precision(class_id=1)\n",
    "m1.update_state(y_true, y_pred)\n",
    "\n",
    "#For class 2\n",
    "m2 = tf.keras.metrics.Precision(class_id=2)\n",
    "m2.update_state(y_true, y_pred)\n",
    "\n",
    "mm = [m0.result().numpy(), m1.result().numpy(), m2.result().numpy()]\n",
    "\n",
    "print('tf.keras precision:',mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-class classification (Average of individual binary scores)\n",
    "\n",
    "y_true = [[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]]\n",
    "y_pred = [[1,0,0],[0,0,1],[0,1,0],[1,0,0],[1,0,0],[0,1,0]]\n",
    "\n",
    "print('sklearn precision (Macro): ',precision_score(y_true, y_pred, average='macro'))\n",
    "print('sklearn precision (Avg of None): ',np.average(precision_score(y_true, y_pred, average=None)))\n",
    "\n",
    "print(' ')\n",
    "\n",
    "print('tf.keras precision:',np.average(mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_gaps(x):\n",
    "    #Identifying the size and shape of the repeating pattern\n",
    "    xpattern = int(x.shape[0]//np.max(x.sum(axis=0))+2)\n",
    "    ypattern = int(x.shape[1]//np.max(x.sum(axis=1))+2)\n",
    "    pattern_shape = (xpattern, ypattern)\n",
    "    \n",
    "    #Calculating number of rolling windows that exist with that pattern\n",
    "    num_xpatterns = x.shape[0]//pattern_shape[0]+1\n",
    "    num_ypatterns = x.shape[1]//pattern_shape[1]+1\n",
    "    \n",
    "    #Calculating the stride and shape that needs to be taken with stride_tricks\n",
    "    shp = (num_xpatterns, num_ypatterns, xpattern, ypattern)  #(2, 2, 3, 5)\n",
    "    strd = (x.strides[0]*(xpattern-1), x.strides[1]*(ypattern-1), x.strides[0], x.strides[1])  #(144, 32, 72, 8)\n",
    "    \n",
    "    #Generating rolling windows/convolutions over the image to separate the patterns.\n",
    "    convolve_pattern = np.lib.stride_tricks.as_strided(x, shape=shp, strides=strd)\n",
    "    \n",
    "    #Assuming at least 1 untouched pattern exists, finding that pure pattern\n",
    "    pattern_sums = convolve_pattern.sum(axis=(-1,-2))\n",
    "    idx = np.unravel_index(np.argmax(pattern_sums), pattern_sums.shape)\n",
    "    truth_pattern = convolve_pattern[idx]\n",
    "    \n",
    "    #Identifying the gaps by subtracting the convolved image with the truth pattern\n",
    "    gaps = convolve_pattern - truth_pattern[None, None, :, :]\n",
    "    \n",
    "    #Setting the gaps as -1 directly into the location of memory of the original image\n",
    "    for i in np.argwhere(gaps==-1):\n",
    "        convolve_pattern[tuple(i)]=-1\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([[1., 0., 0., 0., 1., 0., 0., 0., 0.],  #One gap here\n",
    "                [0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
    "                [1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
    "                [0., 0., 1., 0., 0., 0., 0., 0., 0.],  #One gap here\n",
    "                [1., 0., 0., 0., 1., 0., 0., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([[1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
    "                [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],  #One gap here\n",
    "                [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
    "                [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],  #One gap here\n",
    "                [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
    "                [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
    "                [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]) #Two gaps here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(find_gaps(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.frompyfunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[\"Orange\", \"Carrot\"], [\"Green\", \"Apple\"], [\"Yellow\", \"Banana\"], [\"Orange\", \"Pumpkin\"], [\"Green\", \"Apple\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sum = {'Orange': {'Carrot': 1, 'Pumpkin': 1}, 'Green': {'Apple': 2}, 'Yellow': {'Banana': 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict(Counter([i for sublist in lst for i in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,counts) for i in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_clipboard('\\s\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "training_set = dataset_train.iloc[:,:].values\n",
    "scaled_training_set = sc.fit_transform(training_set)\n",
    "time_step = 3\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(len(training_set)):\n",
    "    X_train.append(scaled_training_set[i-time_step:i,:])\n",
    "    Y_train.append(scaled_training_set[i:i+3,3])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],-1))\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(units=10,return_sequences=False))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(X_train,Y_train.reshape(-1,1),epochs=50,batch_size=time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'Transect':['A','A','B','B','C','C'],\n",
    "      'Easting':[100,101,200,201,306,307],\n",
    "      'Northing':[200,201,200,201,206,207],\n",
    "      'Elev':[2.0,3.0,6.0,7.0,4.0,6.0],\n",
    "      'Dist':[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]}\n",
    "\n",
    "d2 = {'Transect':['A','B','C'],\n",
    "      'Easting':[97,199,298],\n",
    "      'Northing':[198,198,198],\n",
    "      'Elev':[0.0,6.5,8.5],\n",
    "      'Dist':[0,0,0]}\n",
    "\n",
    "df1 = pd.DataFrame(d1)\n",
    "df2 = pd.DataFrame(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the dataframes\n",
    "d1 = {'Transect':['A','A','B','B','C','C'],\n",
    "      'Easting':[100,101,200,201,306,307],\n",
    "      'Northing':[200,201,200,201,206,207],\n",
    "      'Elev':[2.0,3.0,6.0,7.0,4.0,6.0],\n",
    "      'Dist':[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]}\n",
    "\n",
    "d2 = {'Transect':['A','B','C'],\n",
    "      'Easting':[97,199,298],\n",
    "      'Northing':[198,198,198],\n",
    "      'Elev':[0.0,6.5,8.5],\n",
    "      'Dist':[0,0,0]}\n",
    "\n",
    "df1 = pd.DataFrame(d1)\n",
    "df2 = pd.DataFrame(d2)\n",
    "\n",
    "#Selecting columns to keep\n",
    "cols = ['Easting','Northing', 'Elev']\n",
    "\n",
    "#Creating columns with index = Transect to subtract \n",
    "#over this level using Broadcasting\n",
    "a = df1.set_index('Transect')[cols]\n",
    "b = df2.set_index('Transect')[cols]\n",
    "\n",
    "#Formula of distance with elevation\n",
    "#D=√((Long1-Long2)²+(Lat1-Lat2)²+(Alt1-Alt2)²)\n",
    "a['Dist'] = (a.subtract(b, level=0)**2).sum(axis=1)**(1/2)\n",
    "\n",
    "r = pd.concat([a.reset_index(), df2]).sort_values(by = ['Transect', 'Dist'])\n",
    "print(r)\n",
    "\n",
    "  Transect  Easting  Northing  Elev       Dist\n",
    "0        A       97       198   0.0   0.000000\n",
    "0        A      100       200   2.0   4.123106\n",
    "1        A      101       201   3.0   5.830952\n",
    "1        B      199       198   6.5   0.000000\n",
    "2        B      200       200   6.0   2.291288\n",
    "3        B      201       201   7.0   3.640055\n",
    "2        C      298       198   8.5   0.000000\n",
    "4        C      306       206   4.0  12.175796\n",
    "5        C      307       207   6.0  12.971122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Trans': ['A', 'A','B', 'B'],'X': [0.5, 0.5, 1.5, 1.5], 'Y': [2.5, 4.5, 3.5, 6.5]}\n",
    "s = {'Trans': ['A', 'B'],'X': [0.5, 1.5],'Y': [0.5, 1.5]}\n",
    "\n",
    "data= pd.DataFrame(data=d)\n",
    "start = pd.DataFrame(data=s)\n",
    "start['Dist'] = 0.0\n",
    "\n",
    "cols = ['X','Y']\n",
    "a = data.set_index('Trans')[cols]\n",
    "b = start.set_index('Trans')[cols]\n",
    "\n",
    "a['Dist'] = (a.subtract(b, level=0)**2).sum(axis=1)**(1/2)\n",
    "\n",
    "r = pd.concat([a.reset_index(), start]).sort_values(by = ['Trans', 'Dist'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import camera\n",
    "from skimage.transform import rescale, pyramid_gaussian, pyramid_expand, pyramid_reduce\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.data import camera\n",
    "img = camera()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotit(img, up, down):\n",
    "    fig, axes = plt.subplots(1,3, figsize=(10,15))\n",
    "    axes[0].imshow(img)\n",
    "    axes[1].imshow(up)\n",
    "    axes[2].imshow(down)\n",
    "    axes[0].title.set_text('Original')\n",
    "    axes[1].title.set_text('Upsample')\n",
    "    axes[2].title.set_text('Downsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "#from scipy.ndimage import zoom\n",
    "\n",
    "up = zoom(img,2)\n",
    "down = zoom(up,0.5)\n",
    "\n",
    "#161 ms ± 5.49 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(163/1000)/(471/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotit(img, up, down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "up = zoom(img,2, order=0)\n",
    "down = zoom(up,0.5, order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotit(img, up, down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "up = pyramid_expand(img,2)\n",
    "down = pyramid_reduce(up,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotit(img, up, down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "up = pyramid_gaussian(img,2)\n",
    "down = pyramid_gaussian(up,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotit(img, up, down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "up = rescale(img,2, anti_aliasing=False)\n",
    "down = rescale(up,0.5, anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotit(img, up, down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "#from PIL import Image\n",
    "im = Image.fromarray(img)\n",
    "up = im.resize((im.width*2, im.height*2),resample=Image.LANCZOS)\n",
    "down = up.resize((up.width//2, up.height//2),resample=Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotit(img, up, down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100,3,1))\n",
    "y = np.random.randint(0,29,(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, utils\n",
    "\n",
    "\n",
    "#Dummy data and its shapes\n",
    "X = np.random.random((100,3,1)) #(100,3,1)\n",
    "y = np.random.randint(0,29,(100,)) #(100,)\n",
    "\n",
    "\n",
    "#Design model\n",
    "inp = layers.Input((3,1))\n",
    "x = layers.LSTM(64, return_sequences=True)(inp)\n",
    "x = layers.LSTM(64)(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "out = layers.Dense(30, activation='softmax')(x)\n",
    "model = Model(inp, out)\n",
    "\n",
    "#Compile and fit\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=32,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_layer_names=False, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe with same columns\n",
    "d = {'Trans': ['A', 'A','B', 'B'],'X': [0.5, 0.5, 1.5, 1.5], 'Y': [2.5, 4.5, 3.5, 6.5], 'Elev':[3,4,2,5]}\n",
    "s = {'Trans': ['A', 'B'],'X': [0.5, 1.5],'Y': [0.5, 1.5],'Elev':[4,3]}\n",
    "\n",
    "data = pd.DataFrame(data=d)\n",
    "start = pd.DataFrame(data=s)\n",
    "start['Dist'] = 0.0  #Adding Dist column to s\n",
    "\n",
    "#getting X, Y and setting index to \"Trans\"\n",
    "cols = ['X','Y', 'Elev']\n",
    "a = data.set_index('Trans')[cols]\n",
    "b = start.set_index('Trans')[cols]\n",
    "\n",
    "#Calculating broadcasted distance (by index)\n",
    "a['Dist'] = (a.subtract(b, level=0)**2).sum(axis=1)**(1/2)\n",
    "\n",
    "#Stacking start points and calculated points and sorting \n",
    "r = pd.concat([a.reset_index(), start]).sort_values(by = ['Trans', 'Dist'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_clipboard('\\s\\s+')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.read_clipboard('\\s\\s+')\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((a.subtract(b, level=0)**2).sum(axis=1)**(1/2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start['Dist'] = 0.0  #Adding Dist column to s\n",
    "\n",
    "#getting X, Y and setting index to \"Trans\"\n",
    "cols = ['X','Y', 'Elev']\n",
    "a = data.set_index('Trans')[cols]\n",
    "b = start.set_index('Trans')[cols]\n",
    "b = b.loc[a.index.unique()]  #<--- to ensure that same trans elements exist in both\n",
    "\n",
    "#Calculating broadcasted distance (by index)\n",
    "a['Dist'] = list((a.subtract(b, level=0)**2).sum(axis=1)**(1/2))\n",
    "\n",
    "#Stacking start points and calculated points and sorting \n",
    "r = pd.concat([a.reset_index(), start]).sort_values(by = ['Trans', 'Dist'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a.subtract(b, level=0)**2).sum(axis=1)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Dist'] = (a.subtract(b, level=0)**2).sum(axis=1)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('/Users/akshay/Desktop/83145032_10151205469524971_2032796849986863104_n.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = im.width*2, im.height*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_im = im.resize(new, resample=Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_im.save('/Users/akshay/Desktop/upscale.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic3 =  {'1': [A1,A2,A4,A6], '2': [A3,A7] ,'3': [A5] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1 = {'1': 'india','2': 'america','3': 'china'}\n",
    "dic2 = {'A1':'india','A2':'india' ,'A3':'america','A4':'india' ,'A5': 'china','A6': 'india','A7': 'america' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_dic1 = {v:k for k,v in dic1.items()}\n",
    "re_dic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_A=np.arange(17, 29)\n",
    "arr_B=np.arange(17, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_A=np.array([4,4,2,1,1])\n",
    "rep_B=np.array([1,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sublists(arr, rep):\n",
    "    itr = iter(arr)\n",
    "    for size in rep:\n",
    "        sublist = []\n",
    "        for _ in range(size):\n",
    "            sublist.append(next(itr))\n",
    "        yield sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(fetch_sublists(arr_A, rep_A)))\n",
    "print(list(fetch_sublists(arr_B, rep_B)))\n",
    "\n",
    "[[17, 18, 19, 20], [21, 22, 23, 24], [25, 26], [27], [28]]\n",
    "[[17], [18, 19, 20, 21], [22, 23, 24, 25, 26]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_A=np.arange(17, 29)\n",
    "arr_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(rep_A-np.max(rep_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,rep_A.shape[0]*np.max(rep_A)).reshape(rep_A.shape[0],np.max(rep_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((np.max(rep_A),rep_A.shape[0]))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[slice(0,4),0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.eye(4)[:,:2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(n):\n",
    "    q = []\n",
    "    n = np.insert(np.cumsum(rep_A), 0, 0)\n",
    "    for i in range(1, n.shape[0]):\n",
    "        q.append(np.any(np.eye(arr_A.shape[0], dtype=bool)[n[i-1]:n[i]], axis=0))\n",
    "    return np.vstack(q) #np.flipud(np.vstack(q).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrf(rep_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sublists(arr, rep):\n",
    "    itr = iter(arr)\n",
    "    maxlen = np.max(rep)\n",
    "    for size in rep:\n",
    "        sublist = []\n",
    "        for _ in range(size):\n",
    "            sublist.append(next(itr))\n",
    "        yield np.pad(sublist, maxlen-size)[:maxlen]\n",
    "        \n",
    "def get_stars(arr, rep, orientation='right'):\n",
    "    if orientation=='right':\n",
    "        m = np.flipud(list(fetch_sublists(arr, rep)))\n",
    "        star_elements = m[(m!=0).argmax(0), np.arange(m.shape[1])]\n",
    "        m = np.rot90(m,k=-1)\n",
    "    else:\n",
    "        m = np.array(list(fetch_sublists(arr, rep)))\n",
    "        star_elements = np.flip(m[(m!=0).argmax(0), np.arange(m.shape[1])])\n",
    "        m = m.T\n",
    "    return m, star_elements\n",
    "\n",
    "\n",
    "\n",
    "a,b = get_stars(arr_A, rep_A, 'right')\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat, star = get_stars(arr_A, rep_A, 'right')\n",
    "\n",
    "print('Matrix -')\n",
    "print(mat)\n",
    "print('')\n",
    "print('Star elements -')\n",
    "print(star)\n",
    "\n",
    "Matrix -\n",
    "[[17 21  0  0  0]\n",
    " [18 22  0  0  0]\n",
    " [19 23 25  0  0]\n",
    " [20 24 26 27 28]]\n",
    "\n",
    "Star elements -\n",
    "[21 22 25 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(fetch_sublists(arr_A, rep_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m!=0).argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m!=0).argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[:,np.argmax(m, axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_over_axes(f, rep_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "fd = gzip.GzipFile('distance_vector.npy.gz', \"r\")\n",
    "matrix = squareform(np.load(fd))\n",
    "fd.close()\n",
    "clusters = DBSCAN(eps=0.05, min_samples=1, metric=\"precomputed\").fit(np.abs(1-matrix))\n",
    "labels = clusters.labels_\n",
    "print(\"Groups: \", set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = gzip.GzipFile('distance_vector.npy.gz', \"r\")\n",
    "np.load(fd).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = gzip.GzipFile('distance_vector.npy.gz', \"r\")\n",
    "matrix = squareform(np.load(fd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = []\n",
    "for i in range(1,100):\n",
    "    clusters = DBSCAN(eps=i/1000, min_samples=15, metric=\"precomputed\").fit(np.abs())\n",
    "    labels = clusters.labels_\n",
    "    unique_clusters.append(len(set(labels)))\n",
    "        \n",
    "plt.plot(unique_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portnames = [\"PAN\", \"AMS\", \"CAS\", \"NYC\", \"HEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(portnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(itertools.product([1,2,3,4], repeat=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    portnames = [\"PAN\", \"AMS\", \"CAS\", \"NYC\", \"HEL\"]\n",
    "\n",
    "    # don't change this bit - provided in exercise\n",
    "    port1 = 0\n",
    "    for port2 in range(1, 5):\n",
    "        for port3 in range(1, 5):\n",
    "            for port4 in range(1, 5):\n",
    "                for port5 in range(1, 5):\n",
    "                    route = [port1, port2, port3, port4, port5]\n",
    "\n",
    "                    # instructions to add if statement that checks that the route includes all of the ports\n",
    "                    # if \"PAN\" in route and \"AMS\" in route and \"CAS\" in route and \"NYC\" in route and \"HEL\" in route:\n",
    "                    if set(route).issubset(set(portnames)):\n",
    "                    \n",
    "                        # do not modify the print statement\n",
    "                        print(' '.join([portnames[i] for i in route]))\n",
    "\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "portnames = [\"PAN\", \"AMS\", \"CAS\", \"NYC\", \"HEL\"]\n",
    "\n",
    "# don't change this bit - provided in exercise\n",
    "port1 = 0\n",
    "for port2 in range(1, 5):\n",
    "    for port3 in range(1, 5):\n",
    "        for port4 in range(1, 5):\n",
    "            for port5 in range(1, 5):\n",
    "                route = [port1, port2, port3, port4, port5]\n",
    "\n",
    "                # instructions to add if statement that checks that the route includes all of the ports\n",
    "                # if \"PAN\" in route and \"AMS\" in route and \"CAS\" in route and \"NYC\" in route and \"HEL\" in route:\n",
    "                if set(range(len(portnames))).issubset(route):\n",
    "\n",
    "                    # do not modify the print statement\n",
    "                    print(' '.join([portnames[i] for i in route]))\n",
    "\n",
    "                else:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#Load data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#Normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#Reshape\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test.reshape(10000,784)\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print('Data shapes->',[i.shape for i in [x_train, y_train, x_test, y_test]])\n",
    "\n",
    "#Contruct computation graph\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "#Compile with loss as cross_entropy and optimizer as adam\n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Fit model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist \n",
    "from tensorflow.keras import layers, Model, utils\n",
    "\n",
    "#Load data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#Normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#Reshape\n",
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test.reshape(10000,28,28,1)\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "#Set y to onehot instead of label encoded\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "\n",
    "#print([i.shape for i in [x_train, y_train, x_test, y_test]])\n",
    "\n",
    "#Contruct computation graph\n",
    "inp = layers.Input((28,28,1))\n",
    "x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inp)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "out = Dense(10, activation='softmax')(x)\n",
    "\n",
    "#Define model\n",
    "model = Model(inp, out)\n",
    "\n",
    "#Compile with loss as cross_entropy and optimizer as adam\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Fit model\n",
    "#model.fit(x_train, y_train, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_layer_names=False, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data= {'A': [1, 2, 3, 4, 5],\n",
    "                        'test': None})\n",
    "\n",
    "\n",
    "d = {'a' : {\n",
    "        'arg'     : df['A'] == 2,\n",
    "        't_value' : 'Value Found',\n",
    "        'f_value' : df['test']\n",
    "        },\n",
    "     'b' : {\n",
    "        'arg'     : df['A'] > 3,\n",
    "        't_value' : 'Value Found',\n",
    "        'f_value' : df['test']\n",
    "        }\n",
    "     }\n",
    "\n",
    "for item in d:\n",
    "    df['test'] = np.where(d[item]['arg'], d[item]['t_value'], d[item]['f_value'])\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data= {'A': [1, 2, 3, 4, 5],\n",
    "                        'test': None})\n",
    "\n",
    "#conditions\n",
    "a = df['A']==2 \n",
    "b = df['A']>3\n",
    "\n",
    "\n",
    "df['test'] = df['test'].where(~(a|b), 'Value Found')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test'].where(~((df['A']==2) | (df['A']>3)), 'Value Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in d:\n",
    "    df['test'] = np.where(d[item]['arg'], d[item]['t_value'], d[item]['f_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'hithere'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_character = [i[1] for i in zip(s, s[1:])]\n",
    "\n",
    "print(next_character)\n",
    "\n",
    "\n",
    "#['i', 'v', 'e', 'm', 'e', 't', 'h', 'e', 'n', 'e', 'x', 't', 'c', 'h', 'a', 'r', 'a', 'c', 't', 'e', 'r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(s, s[1:]):\n",
    "    print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
