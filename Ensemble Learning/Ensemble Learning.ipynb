{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit, X_eval, Y_fit, Y_test = model_selection.train_test_split(X,Y,test_size = 0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=7, shuffle=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=5,random_state=7)\n",
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=100, n_jobs=1, oob_score=False,\n",
       "         random_state=7, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees,random_state=seed)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.95238095, 1.        , 0.9047619 , 0.85714286])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model, X_fit, Y_fit, cv=kfold)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0  accuracy  1.0\n",
      "model  1  accuracy  0.9523809523809523\n",
      "model  2  accuracy  1.0\n",
      "model  3  accuracy  0.9047619047619048\n",
      "model  4  accuracy  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "x = [print(\"model \",i,\" accuracy \",results[i]) for i in range(0,len(results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy  0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy \",results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit, X_eval, Y_fit, Y_test = model_selection.train_test_split(X,Y,test_size = 0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.1, n_estimators=25, random_state=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier(base_estimator=cart, n_estimators=num_trees, learning_rate=0.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseWeightBoosting.staged_score at 0x107c5c620>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.staged_score(X_fit,Y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = model.predict(X_eval)\n",
    "nnz = np.float(np.shape(Y_test)[0] - np.count_nonzero(pred_label - Y_test))\n",
    "acc = 100*nnz/np.shape(Y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.66666666666667"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = iris.data[:,1:3], iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy(y_test,pred_label):\n",
    "    nnz = np.shape(y_test)[0] - np.count_nonzero(pred_label - y_test)\n",
    "    acc = 100*nnz/float(np.shape(y_test)[0])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=2)\n",
    "clf2 = RandomForestClassifier(n_estimators=2, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X,y)\n",
    "clf2.fit(X,y)\n",
    "clf3.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.66666666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = clf1.predict(X)\n",
    "acc1 = CalculateAccuracy(y,f1)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.66666666666667"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = clf2.predict(X)\n",
    "acc2 = CalculateAccuracy(y,f2)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3 = clf3.predict(X)\n",
    "acc3 = CalculateAccuracy(y,f3)\n",
    "acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [f1,f2,f3]\n",
    "f = np.transpose(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(f,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = lr.predict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4 = CalculateAccuracy(y,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.33333333333333"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'Name':['Person 1','Person 2','Person 3','Person 4','Person 5','Person 6','Person 7','Person 8','Person 9','Person 10'],\n",
    "           'Salary':['Low','Med','Med','Med','Med','High','Low','High','Med','Low'],\n",
    "           'Sex':['Male','Male','Male','Female','Male','Female','Female','Male','Female','Male'],\n",
    "           'Marital':['Unmarried','Unmarried','Married','Married','Married','Unmarried','Unmarried','Unmarried','Unmarried','Married'],\n",
    "           'Class':['No','No','Yes','No','Yes','Yes','No','Yes','Yes','Yes']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person 1</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person 2</td>\n",
       "      <td>Med</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person 3</td>\n",
       "      <td>Med</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Person 4</td>\n",
       "      <td>Med</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Person 5</td>\n",
       "      <td>Med</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Person 6</td>\n",
       "      <td>High</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Person 7</td>\n",
       "      <td>Low</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Person 8</td>\n",
       "      <td>High</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Person 9</td>\n",
       "      <td>Med</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Person 10</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Salary     Sex    Marital Class\n",
       "0   Person 1    Low    Male  Unmarried    No\n",
       "1   Person 2    Med    Male  Unmarried    No\n",
       "2   Person 3    Med    Male    Married   Yes\n",
       "3   Person 4    Med  Female    Married    No\n",
       "4   Person 5    Med    Male    Married   Yes\n",
       "5   Person 6   High  Female  Unmarried   Yes\n",
       "6   Person 7    Low  Female  Unmarried    No\n",
       "7   Person 8   High    Male  Unmarried   Yes\n",
       "8   Person 9    Med  Female  Unmarried   Yes\n",
       "9  Person 10    Low    Male    Married   Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy of classes\n",
    "1. Degree of randomness or uncertainity\n",
    "2. Degree of variance\n",
    "3. Class variance\n",
    "4. Measure of impurity (if all instance are same class then entropy is 0, pure dataset)\n",
    "\n",
    "### Mutual Information\n",
    "1. Its a measure to select the most informative attribute\n",
    "2. Select an attribute that is used to reduce entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassEntropy(classAttributes):\n",
    "    #get disctinct classes and how many time they occur\n",
    "    _,counts = np.unique(classAttributes, return_counts=True)\n",
    "    denom = len(classAttributes)\n",
    "    entropy = 0\n",
    "    #Loop to calculate entropy for dataset\n",
    "    for count in counts:\n",
    "        fraction = count/denom\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name -> 3.321928094887362\n",
      "Salary -> 1.4854752972273344\n",
      "Sex -> 0.9709505944546686\n",
      "Marital -> 0.9709505944546686\n",
      "Class -> 0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "#Entropy for our target variable - Class\n",
    "for i in list(df.columns):\n",
    "    print(i,\"->\",getClassEntropy(df[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Entropy?\n",
    "\n",
    "What is entropy, fundamentally?\n",
    "\n",
    "Entropy deals with the number of \"microstates\" that are consistent with a given \"macrostate\". For example, if I tell you only macroscopic properties of a container of gas (e.g., volume, pressure, energy, number of molecules, etc.), there are still lots of different ways of arranging the individual molecules (in terms of position, momentum, angular momentum, vibrations, etc.) that would be \"allowed\". Entropy talks about how many such states there are.\n",
    "\n",
    "What happens when we talk about the combination of two systems?\n",
    "\n",
    "Say we have two containers of gas, and we know the macroscopic properties of both. There are N1 possible \"microstates\" for the first container, and N2 for the second. What are the possible microstates for the system that consists of both containers? Well, for each microstate of one container, all of the microstates of the other are still allowed. We can literally pick one of the allowed microstates for each container, and that combination will be a valid microstate for the whole system. So, the total number of microstates is given by the product:\n",
    "\n",
    "Ntot=N1⋅N2.\n",
    "\n",
    "How would we like to be able to talk about combinations of systems?\n",
    "\n",
    "Clearly, when you include more things in your system, the number of microstates increases. There are lots of things that act like this: total mass, total volume, etc. There's a broad class of these called extensive properties (see: Intensive and extensive properties), which are very convenient to work with. They're convenient, because to consider the combination of two sub-systems, you just have to add the relevant quantities together (like for mass, volume, energy, etc.) Unfortunately, number of microstates doesn't behave that way. As shown above, the relevant quantities need to be multiplied, not added, which is harder to work with.\n",
    "\n",
    "How do we solve this problem?\n",
    "\n",
    "It's a basic property of logarithms that\n",
    "\n",
    "log(ab)=log(a)+log(b),\n",
    "\n",
    "i.e., it turns multiplication into addition. Applying this to our microstates example, we get that\n",
    "\n",
    "log(N1N2)=log(N1)+log(N2).\n",
    "\n",
    "So, if we define entropy to be proportional to the log (in any base) of the number of microstates, then entropy suddenly becomes an extensive property of a system, and thus much easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is entropy measured in log?\n",
    "\n",
    "It's because entropy is a type of information, and the easiest way to measure information is in bits and bytes, rather than by the total number of possible states they can represent.\n",
    "\n",
    "Entropy is the amount of information contained in the microscopic state of a system which is missing in the approximate representation of that system using macroscopic thermodynamics.\n",
    "\n",
    "The basic unit of information is the bit, which represents 2 possible states.  If you have n bits, then that information represents 2^n possible states.  For example, a byte is 8 bits, therefore the number of states it represents is 28=256.  That means that a byte can store any number between 0 and 255.  If you are given the total number of states, then you just take the log of that number to get the amount of information, measured in bits:  log2256=8.  \n",
    "\n",
    "So entropy is defined as the log of the number of total microscopic states corresponding to a particular macro state of thermodynamics.  This is the additional information you'd need to know in order to completely specify the microstate, given knowledge of the macrostate.  \n",
    "\n",
    "Ok, but then you might ask:  why is information measured with logarithms instead of just by the total number of states?  Mostly because it makes it additive.  It's true that if you really wanted to, you could choose to measure information or entropy by the total number of states (usually called the \"multiplicity\"),  instead of by the log of the multiplicity.  But then it would be multiplicative instead of additive.  If you have 10 bits and then you obtain another 10 bits of information, then you have 20 bits.  Saying the same thing in terms of multiplicity:  if you have 2^10 = 1024 states and then you add another 1024 independent states then you have 1024*1024 = 1048576 states (2^20) when they are combined.  Multiplicity is multiplicative instead of additative, which means that the numbers you need in order to keep track of it get very large very quickly!  This is really inconvenient, hence why we usually stick with using information/entropy as the unit instead of multiplicity.\n",
    "\n",
    "The only funny thing you might notice here is that in computer science, information is usually measured in units defined by the log base 2 of the number of states, whereas in physics entropy is usually measured in units defined by the natural log (log base e).  This is purely a difference of convention.  Physicists like to use natural logs because they're used to using them for many other things and they have nice mathematical properties.  But there's a good case to be made that bits (log base 2) is the more natural unit to measure entropy in.  I wouldn't be too surprised if, in the future, it becomes more common for physicists to switch to this convention.  (In some areas of physics, such as quantum computing and quantum information, this new convention has already started being adopted.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHistTable(df, attribute):\n",
    "    value = df[attribute]\n",
    "    classes = df['Class']\n",
    "    classunique = df['Class'].unique()\n",
    "    valunique = df[attribute].unique()\n",
    "    temp = np.zeros((len(classunique),len(valunique)))\n",
    "    histTable = pd.DataFrame(temp, index = classunique, columns = valunique)\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        histTable[value[i]][classes[i]]+=1\n",
    "    return histTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Med</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Low  Med  High\n",
       "No   2.0  2.0   0.0\n",
       "Yes  1.0  3.0   2.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getHistTable(df,'Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
