{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras-Sklearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('auto-mpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['horsepower']!='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshay/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1['horsepower'] = [int(i) for i in df1['horsepower']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.445918</td>\n",
       "      <td>5.471939</td>\n",
       "      <td>194.411990</td>\n",
       "      <td>104.469388</td>\n",
       "      <td>2977.584184</td>\n",
       "      <td>15.541327</td>\n",
       "      <td>75.979592</td>\n",
       "      <td>1.576531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.805007</td>\n",
       "      <td>1.705783</td>\n",
       "      <td>104.644004</td>\n",
       "      <td>38.491160</td>\n",
       "      <td>849.402560</td>\n",
       "      <td>2.758864</td>\n",
       "      <td>3.683737</td>\n",
       "      <td>0.805518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1613.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2225.250000</td>\n",
       "      <td>13.775000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>2803.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>275.750000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>3614.750000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mpg   cylinders  displacement  horsepower       weight  \\\n",
       "count  392.000000  392.000000    392.000000  392.000000   392.000000   \n",
       "mean    23.445918    5.471939    194.411990  104.469388  2977.584184   \n",
       "std      7.805007    1.705783    104.644004   38.491160   849.402560   \n",
       "min      9.000000    3.000000     68.000000   46.000000  1613.000000   \n",
       "25%     17.000000    4.000000    105.000000   75.000000  2225.250000   \n",
       "50%     22.750000    4.000000    151.000000   93.500000  2803.500000   \n",
       "75%     29.000000    8.000000    275.750000  126.000000  3614.750000   \n",
       "max     46.600000    8.000000    455.000000  230.000000  5140.000000   \n",
       "\n",
       "       acceleration  model year      origin  \n",
       "count    392.000000  392.000000  392.000000  \n",
       "mean      15.541327   75.979592    1.576531  \n",
       "std        2.758864    3.683737    0.805518  \n",
       "min        8.000000   70.000000    1.000000  \n",
       "25%       13.775000   73.000000    1.000000  \n",
       "50%       15.500000   76.000000    1.000000  \n",
       "75%       17.025000   79.000000    2.000000  \n",
       "max       24.800000   82.000000    3.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['mpg']\n",
    "X = df1.drop('mpg', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cylinders  displacement  horsepower  weight  acceleration  model year  \\\n",
       "0          8         307.0         130    3504          12.0          70   \n",
       "1          8         350.0         165    3693          11.5          70   \n",
       "2          8         318.0         150    3436          11.0          70   \n",
       "3          8         304.0         150    3433          12.0          70   \n",
       "4          8         302.0         140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autompg_model():\n",
    "    inp = Input((8,))\n",
    "    x = Dense(16, activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1)(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',\n",
       "       'model year', 'origin', 'car name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['car name']\n",
    "num_cols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin']\n",
    "\n",
    "encoding = ('encoding', OrdinalEncoder(), cat_cols)\n",
    "standard = ('standard', StandardScaler(), num_cols)\n",
    "\n",
    "steps = [standard, encoding]\n",
    "ct = ColumnTransformer(steps, remainder='passthrough')\n",
    "\n",
    "preprocess = ('preprocess', ct)\n",
    "regress = ('reg', KerasRegressor(build_fn=autompg_model, epochs=500, verbose=1, validation_split=0.15))\n",
    "steps1 = [preprocess, regress]\n",
    "\n",
    "pipe = Pipeline(steps1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocess', ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('standard', StandardScaler(copy=True, with_mean=True, with_std=True), ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin']), ('encoding', OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>), ['car name'])])), ('reg', <keras.wrappers.scikit_learn.KerasRegressor object at 0x1a291cab70>)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshay/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/akshay/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 333 samples, validate on 59 samples\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 3669.6905 - val_loss: 1704.9543\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 2770.0076 - val_loss: 1280.2888\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 2630.4158 - val_loss: 992.3317\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 1542.3789 - val_loss: 855.7027\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 1986.9772 - val_loss: 754.7924\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 1504.5119 - val_loss: 692.6478\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 1435.4904 - val_loss: 663.6307\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 0s 117us/step - loss: 1208.5310 - val_loss: 648.0515\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 0s 133us/step - loss: 1009.2290 - val_loss: 624.8765\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 943.9464 - val_loss: 610.2237\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 0s 107us/step - loss: 876.1507 - val_loss: 592.8699\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 903.4195 - val_loss: 585.9479\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 783.7805 - val_loss: 585.0131\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 706.0060 - val_loss: 580.6152\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 815.2200 - val_loss: 564.0783\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 730.4810 - val_loss: 555.8687\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 742.5739 - val_loss: 553.7748\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 684.8542 - val_loss: 547.4554\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 0s 117us/step - loss: 624.4528 - val_loss: 538.9342\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 567.9432 - val_loss: 529.5042\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 577.0143 - val_loss: 526.6057\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 533.5154 - val_loss: 531.4598\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 0s 102us/step - loss: 475.6504 - val_loss: 522.0487\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 519.7020 - val_loss: 506.6346\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 538.9280 - val_loss: 496.5236\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 469.1665 - val_loss: 492.2358\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 519.1921 - val_loss: 494.1989\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 463.7791 - val_loss: 498.9715\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 394.1420 - val_loss: 500.5359\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 0s 135us/step - loss: 424.3320 - val_loss: 501.5276\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 0s 138us/step - loss: 456.7015 - val_loss: 498.2712\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 0s 112us/step - loss: 416.2597 - val_loss: 498.4202\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 0s 126us/step - loss: 432.4742 - val_loss: 494.5193\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 402.4751 - val_loss: 494.3942\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 0s 135us/step - loss: 394.7063 - val_loss: 494.5781\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 0s 137us/step - loss: 408.6672 - val_loss: 498.1188\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 0s 146us/step - loss: 337.6813 - val_loss: 509.3378\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 0s 142us/step - loss: 366.5170 - val_loss: 515.1571\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 372.2422 - val_loss: 515.6100\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 356.0436 - val_loss: 517.8243\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 0s 108us/step - loss: 345.9663 - val_loss: 519.8167\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 0s 103us/step - loss: 346.5458 - val_loss: 524.6090\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 343.2180 - val_loss: 527.0354\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 359.7231 - val_loss: 532.6114\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 384.1593 - val_loss: 544.6754\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 331.2887 - val_loss: 551.2388\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 0s 126us/step - loss: 304.9032 - val_loss: 550.6683\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 323.2866 - val_loss: 533.9092\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 0s 157us/step - loss: 317.2489 - val_loss: 526.7807\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 297.9097 - val_loss: 526.6284\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 298.4012 - val_loss: 529.8570\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 0s 160us/step - loss: 296.4337 - val_loss: 515.2036\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 0s 161us/step - loss: 286.2618 - val_loss: 514.1148\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 0s 167us/step - loss: 289.7771 - val_loss: 509.9361\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 0s 107us/step - loss: 300.1069 - val_loss: 501.1087\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 0s 108us/step - loss: 341.9484 - val_loss: 518.2677\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 303.1180 - val_loss: 527.7656\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 0s 113us/step - loss: 285.2231 - val_loss: 520.5669\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 0s 106us/step - loss: 270.6112 - val_loss: 510.5428\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 279.4740 - val_loss: 511.1488\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 0s 108us/step - loss: 276.1996 - val_loss: 509.8634\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 293.0477 - val_loss: 520.4356\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 0s 98us/step - loss: 297.1663 - val_loss: 526.8133\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 0s 103us/step - loss: 308.7280 - val_loss: 532.5536\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 0s 106us/step - loss: 276.5525 - val_loss: 523.5737\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 0s 100us/step - loss: 265.8147 - val_loss: 505.6427\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 271.6347 - val_loss: 493.0229\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 294.7459 - val_loss: 489.1439\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 259.8386 - val_loss: 489.5350\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 269.7652 - val_loss: 495.1171\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 0s 112us/step - loss: 266.6480 - val_loss: 511.1805\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 264.5871 - val_loss: 513.0650\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 282.5009 - val_loss: 515.4351\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 268.4379 - val_loss: 525.8440\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 0s 104us/step - loss: 279.8519 - val_loss: 516.8052\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 0s 101us/step - loss: 253.3856 - val_loss: 524.0343\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 0s 108us/step - loss: 275.1640 - val_loss: 524.7149\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 0s 106us/step - loss: 252.0722 - val_loss: 521.4051\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 264.7231 - val_loss: 514.0887\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 247.6595 - val_loss: 496.4197\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 271.7449 - val_loss: 479.2736\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 251.5188 - val_loss: 510.4979\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 239.4091 - val_loss: 524.7200\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 0s 103us/step - loss: 259.9930 - val_loss: 523.8181\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 246.7372 - val_loss: 516.9524\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 0s 147us/step - loss: 258.2751 - val_loss: 519.9492\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 0s 145us/step - loss: 249.3009 - val_loss: 517.5468\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 237.7045 - val_loss: 512.6108\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 258.2374 - val_loss: 503.6225\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 250.4699 - val_loss: 496.8938\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 0s 113us/step - loss: 261.6681 - val_loss: 488.2789\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 237.7845 - val_loss: 487.3594\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 247.8992 - val_loss: 502.3424\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 0s 156us/step - loss: 241.8571 - val_loss: 503.8389\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 0s 137us/step - loss: 251.7192 - val_loss: 492.1225\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 0s 144us/step - loss: 236.6125 - val_loss: 478.2166\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 214.9094 - val_loss: 473.8261\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 0s 112us/step - loss: 246.3696 - val_loss: 460.3385\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 0s 112us/step - loss: 260.2886 - val_loss: 472.7649\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 243.5727 - val_loss: 497.0810\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 237.9222 - val_loss: 498.7815\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 234.2978 - val_loss: 487.4904\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 242.9546 - val_loss: 470.6920\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 0s 151us/step - loss: 244.1190 - val_loss: 466.6487\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 0s 141us/step - loss: 225.3974 - val_loss: 477.7384\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 201.5745 - val_loss: 482.0472\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 228.7414 - val_loss: 486.8165\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 234.5211 - val_loss: 490.2547\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 243.0108 - val_loss: 486.9324\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 0s 117us/step - loss: 227.2777 - val_loss: 497.9873\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 241.2944 - val_loss: 498.8660\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 218.3906 - val_loss: 492.4234\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 228.5419 - val_loss: 491.9821\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 223.9041 - val_loss: 478.6278\n",
      "Epoch 115/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 212.2020 - val_loss: 469.5096\n",
      "Epoch 116/500\n",
      "333/333 [==============================] - 0s 107us/step - loss: 214.5721 - val_loss: 469.1579\n",
      "Epoch 117/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 232.4290 - val_loss: 461.2757\n",
      "Epoch 118/500\n",
      "333/333 [==============================] - 0s 305us/step - loss: 215.3409 - val_loss: 459.8691\n",
      "Epoch 119/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 205.7265 - val_loss: 453.7973\n",
      "Epoch 120/500\n",
      "333/333 [==============================] - 0s 201us/step - loss: 212.4800 - val_loss: 456.0128\n",
      "Epoch 121/500\n",
      "333/333 [==============================] - 0s 152us/step - loss: 231.6277 - val_loss: 462.5992\n",
      "Epoch 122/500\n",
      "333/333 [==============================] - 0s 146us/step - loss: 202.4376 - val_loss: 456.7374\n",
      "Epoch 123/500\n",
      "333/333 [==============================] - 0s 105us/step - loss: 217.9309 - val_loss: 453.2327\n",
      "Epoch 124/500\n",
      "333/333 [==============================] - 0s 143us/step - loss: 229.7360 - val_loss: 449.3856\n",
      "Epoch 125/500\n",
      "333/333 [==============================] - 0s 173us/step - loss: 224.2123 - val_loss: 445.7934\n",
      "Epoch 126/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 209.4083 - val_loss: 446.8480\n",
      "Epoch 127/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 196.0748 - val_loss: 441.6409\n",
      "Epoch 128/500\n",
      "333/333 [==============================] - 0s 151us/step - loss: 224.4988 - val_loss: 436.7315\n",
      "Epoch 129/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 207.0078 - val_loss: 438.3313\n",
      "Epoch 130/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 205.7674 - val_loss: 426.5782\n",
      "Epoch 131/500\n",
      "333/333 [==============================] - 0s 165us/step - loss: 202.8913 - val_loss: 426.9234\n",
      "Epoch 132/500\n",
      "333/333 [==============================] - 0s 175us/step - loss: 210.6200 - val_loss: 452.8771\n",
      "Epoch 133/500\n",
      "333/333 [==============================] - 0s 141us/step - loss: 215.9215 - val_loss: 446.4816\n",
      "Epoch 134/500\n",
      "333/333 [==============================] - 0s 186us/step - loss: 211.5951 - val_loss: 437.3665\n",
      "Epoch 135/500\n",
      "333/333 [==============================] - 0s 326us/step - loss: 206.2313 - val_loss: 435.9196\n",
      "Epoch 136/500\n",
      "333/333 [==============================] - 0s 163us/step - loss: 197.3667 - val_loss: 442.4923\n",
      "Epoch 137/500\n",
      "333/333 [==============================] - 0s 239us/step - loss: 213.9931 - val_loss: 439.0512\n",
      "Epoch 138/500\n",
      "333/333 [==============================] - 0s 155us/step - loss: 214.6614 - val_loss: 440.9609\n",
      "Epoch 139/500\n",
      "333/333 [==============================] - 0s 280us/step - loss: 198.6765 - val_loss: 467.0545\n",
      "Epoch 140/500\n",
      "333/333 [==============================] - 0s 153us/step - loss: 197.9035 - val_loss: 455.6886\n",
      "Epoch 141/500\n",
      "333/333 [==============================] - 0s 170us/step - loss: 219.2327 - val_loss: 439.7748\n",
      "Epoch 142/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 194.7121 - val_loss: 426.4326\n",
      "Epoch 143/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 192.1452 - val_loss: 417.2599\n",
      "Epoch 144/500\n",
      "333/333 [==============================] - 0s 133us/step - loss: 180.7504 - val_loss: 418.3038\n",
      "Epoch 145/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 200.0135 - val_loss: 408.3200\n",
      "Epoch 146/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 202.9207 - val_loss: 399.0256\n",
      "Epoch 147/500\n",
      "333/333 [==============================] - 0s 146us/step - loss: 217.6047 - val_loss: 383.6240\n",
      "Epoch 148/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 210.4330 - val_loss: 370.9195\n",
      "Epoch 149/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 215.8445 - val_loss: 371.7000\n",
      "Epoch 150/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 176.3215 - val_loss: 363.2271\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 0s 214us/step - loss: 191.5799 - val_loss: 375.3917\n",
      "Epoch 152/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 187.2278 - val_loss: 372.0410\n",
      "Epoch 153/500\n",
      "333/333 [==============================] - 0s 175us/step - loss: 191.4754 - val_loss: 393.3813\n",
      "Epoch 154/500\n",
      "333/333 [==============================] - 0s 146us/step - loss: 203.7404 - val_loss: 413.3988\n",
      "Epoch 155/500\n",
      "333/333 [==============================] - 0s 147us/step - loss: 197.0313 - val_loss: 413.8624\n",
      "Epoch 156/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 188.2681 - val_loss: 394.5369\n",
      "Epoch 157/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 190.2394 - val_loss: 375.2547\n",
      "Epoch 158/500\n",
      "333/333 [==============================] - 0s 144us/step - loss: 163.1207 - val_loss: 366.7146\n",
      "Epoch 159/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 197.4148 - val_loss: 370.6761\n",
      "Epoch 160/500\n",
      "333/333 [==============================] - 0s 142us/step - loss: 175.5542 - val_loss: 366.9509\n",
      "Epoch 161/500\n",
      "333/333 [==============================] - 0s 197us/step - loss: 183.8347 - val_loss: 384.4654\n",
      "Epoch 162/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 191.8193 - val_loss: 375.0040\n",
      "Epoch 163/500\n",
      "333/333 [==============================] - 0s 153us/step - loss: 184.9554 - val_loss: 366.4378\n",
      "Epoch 164/500\n",
      "333/333 [==============================] - 0s 230us/step - loss: 186.9014 - val_loss: 352.7092\n",
      "Epoch 165/500\n",
      "333/333 [==============================] - 0s 140us/step - loss: 184.0534 - val_loss: 347.0315\n",
      "Epoch 166/500\n",
      "333/333 [==============================] - 0s 166us/step - loss: 170.7391 - val_loss: 352.0091\n",
      "Epoch 167/500\n",
      "333/333 [==============================] - 0s 162us/step - loss: 180.0542 - val_loss: 369.6860\n",
      "Epoch 168/500\n",
      "333/333 [==============================] - 0s 169us/step - loss: 191.7793 - val_loss: 359.4461\n",
      "Epoch 169/500\n",
      "333/333 [==============================] - 0s 158us/step - loss: 186.5888 - val_loss: 350.7296\n",
      "Epoch 170/500\n",
      "333/333 [==============================] - 0s 143us/step - loss: 160.9995 - val_loss: 341.2840\n",
      "Epoch 171/500\n",
      "333/333 [==============================] - 0s 126us/step - loss: 164.0496 - val_loss: 326.5413\n",
      "Epoch 172/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 179.4402 - val_loss: 329.4614\n",
      "Epoch 173/500\n",
      "333/333 [==============================] - 0s 144us/step - loss: 171.8616 - val_loss: 316.0089\n",
      "Epoch 174/500\n",
      "333/333 [==============================] - 0s 152us/step - loss: 202.9651 - val_loss: 316.3922\n",
      "Epoch 175/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 176.6549 - val_loss: 321.4037\n",
      "Epoch 176/500\n",
      "333/333 [==============================] - 0s 148us/step - loss: 167.2510 - val_loss: 325.0688\n",
      "Epoch 177/500\n",
      "333/333 [==============================] - 0s 142us/step - loss: 173.9039 - val_loss: 313.1809\n",
      "Epoch 178/500\n",
      "333/333 [==============================] - 0s 126us/step - loss: 172.3434 - val_loss: 305.6695\n",
      "Epoch 179/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 175.7735 - val_loss: 294.5432\n",
      "Epoch 180/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 169.9675 - val_loss: 294.2881\n",
      "Epoch 181/500\n",
      "333/333 [==============================] - 0s 161us/step - loss: 183.8107 - val_loss: 325.1207\n",
      "Epoch 182/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 165.6435 - val_loss: 328.2864\n",
      "Epoch 183/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 163.3948 - val_loss: 300.4320\n",
      "Epoch 184/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 152.0801 - val_loss: 271.3321\n",
      "Epoch 185/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 167.7003 - val_loss: 286.4745\n",
      "Epoch 186/500\n",
      "333/333 [==============================] - 0s 117us/step - loss: 161.5667 - val_loss: 295.2754\n",
      "Epoch 187/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 169.1567 - val_loss: 299.9841\n",
      "Epoch 188/500\n",
      "333/333 [==============================] - 0s 100us/step - loss: 184.2512 - val_loss: 298.7588\n",
      "Epoch 189/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 161.8255 - val_loss: 295.5264\n",
      "Epoch 190/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 167.5374 - val_loss: 282.4511\n",
      "Epoch 191/500\n",
      "333/333 [==============================] - 0s 112us/step - loss: 154.9096 - val_loss: 272.1960\n",
      "Epoch 192/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 159.6471 - val_loss: 260.0767\n",
      "Epoch 193/500\n",
      "333/333 [==============================] - 0s 201us/step - loss: 146.2142 - val_loss: 263.7700\n",
      "Epoch 194/500\n",
      "333/333 [==============================] - 0s 165us/step - loss: 162.4042 - val_loss: 265.5423\n",
      "Epoch 195/500\n",
      "333/333 [==============================] - 0s 163us/step - loss: 160.9663 - val_loss: 268.2769\n",
      "Epoch 196/500\n",
      "333/333 [==============================] - 0s 145us/step - loss: 145.8931 - val_loss: 278.3989\n",
      "Epoch 197/500\n",
      "333/333 [==============================] - 0s 142us/step - loss: 135.8352 - val_loss: 253.2571\n",
      "Epoch 198/500\n",
      "333/333 [==============================] - 0s 153us/step - loss: 154.3256 - val_loss: 271.7209\n",
      "Epoch 199/500\n",
      "333/333 [==============================] - 0s 143us/step - loss: 132.8381 - val_loss: 253.2283\n",
      "Epoch 200/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 150.3961 - val_loss: 232.3767\n",
      "Epoch 201/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 144.6861 - val_loss: 240.5264\n",
      "Epoch 202/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 151.1315 - val_loss: 245.5187\n",
      "Epoch 203/500\n",
      "333/333 [==============================] - 0s 142us/step - loss: 147.3785 - val_loss: 228.2480\n",
      "Epoch 204/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 121.6231 - val_loss: 229.7888\n",
      "Epoch 205/500\n",
      "333/333 [==============================] - 0s 165us/step - loss: 129.2504 - val_loss: 203.5014\n",
      "Epoch 206/500\n",
      "333/333 [==============================] - 0s 187us/step - loss: 160.3047 - val_loss: 224.6544\n",
      "Epoch 207/500\n",
      "333/333 [==============================] - 0s 217us/step - loss: 134.0635 - val_loss: 211.6957\n",
      "Epoch 208/500\n",
      "333/333 [==============================] - 0s 203us/step - loss: 129.1266 - val_loss: 176.7117\n",
      "Epoch 209/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 149.1682 - val_loss: 167.3308\n",
      "Epoch 210/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 137.7888 - val_loss: 171.0019\n",
      "Epoch 211/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 138.8259 - val_loss: 168.9773\n",
      "Epoch 212/500\n",
      "333/333 [==============================] - 0s 160us/step - loss: 130.4031 - val_loss: 196.6794\n",
      "Epoch 213/500\n",
      "333/333 [==============================] - 0s 147us/step - loss: 141.9837 - val_loss: 190.2159\n",
      "Epoch 214/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 123.8995 - val_loss: 188.5293\n",
      "Epoch 215/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 136.3082 - val_loss: 184.6963\n",
      "Epoch 216/500\n",
      "333/333 [==============================] - 0s 153us/step - loss: 113.4242 - val_loss: 164.5284\n",
      "Epoch 217/500\n",
      "333/333 [==============================] - 0s 137us/step - loss: 129.8673 - val_loss: 162.2056\n",
      "Epoch 218/500\n",
      "333/333 [==============================] - 0s 133us/step - loss: 127.2705 - val_loss: 146.0179\n",
      "Epoch 219/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 119.0399 - val_loss: 165.7926\n",
      "Epoch 220/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 132.6153 - val_loss: 157.8804\n",
      "Epoch 221/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 130.3750 - val_loss: 175.2655\n",
      "Epoch 222/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 124.1593 - val_loss: 162.9881\n",
      "Epoch 223/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 115.7707 - val_loss: 142.6902\n",
      "Epoch 224/500\n",
      "333/333 [==============================] - 0s 250us/step - loss: 125.8234 - val_loss: 161.0143\n",
      "Epoch 225/500\n",
      "333/333 [==============================] - 0s 205us/step - loss: 121.3396 - val_loss: 171.3059\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 0s 134us/step - loss: 111.0028 - val_loss: 156.2659\n",
      "Epoch 227/500\n",
      "333/333 [==============================] - 0s 147us/step - loss: 117.5950 - val_loss: 147.7024\n",
      "Epoch 228/500\n",
      "333/333 [==============================] - 0s 157us/step - loss: 130.7293 - val_loss: 123.6936\n",
      "Epoch 229/500\n",
      "333/333 [==============================] - 0s 150us/step - loss: 110.9036 - val_loss: 143.1497\n",
      "Epoch 230/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 116.5335 - val_loss: 162.2581\n",
      "Epoch 231/500\n",
      "333/333 [==============================] - 0s 118us/step - loss: 123.2647 - val_loss: 155.0701\n",
      "Epoch 232/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 113.6306 - val_loss: 139.6839\n",
      "Epoch 233/500\n",
      "333/333 [==============================] - 0s 137us/step - loss: 114.9020 - val_loss: 133.2990\n",
      "Epoch 234/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 129.6287 - val_loss: 164.4964\n",
      "Epoch 235/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 117.5151 - val_loss: 153.9060\n",
      "Epoch 236/500\n",
      "333/333 [==============================] - 0s 106us/step - loss: 123.1816 - val_loss: 175.7151\n",
      "Epoch 237/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 113.6692 - val_loss: 134.0815\n",
      "Epoch 238/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 125.9258 - val_loss: 124.7076\n",
      "Epoch 239/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 114.9089 - val_loss: 140.1978\n",
      "Epoch 240/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 117.8629 - val_loss: 149.7195\n",
      "Epoch 241/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 119.1064 - val_loss: 148.8540\n",
      "Epoch 242/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 108.7293 - val_loss: 119.9999\n",
      "Epoch 243/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 121.3852 - val_loss: 127.6986\n",
      "Epoch 244/500\n",
      "333/333 [==============================] - 0s 178us/step - loss: 106.8714 - val_loss: 130.8509\n",
      "Epoch 245/500\n",
      "333/333 [==============================] - 0s 172us/step - loss: 108.7782 - val_loss: 126.3647\n",
      "Epoch 246/500\n",
      "333/333 [==============================] - 0s 145us/step - loss: 103.3000 - val_loss: 129.6188\n",
      "Epoch 247/500\n",
      "333/333 [==============================] - 0s 92us/step - loss: 119.1195 - val_loss: 95.7493\n",
      "Epoch 248/500\n",
      "333/333 [==============================] - 0s 92us/step - loss: 115.9494 - val_loss: 100.9707\n",
      "Epoch 249/500\n",
      "333/333 [==============================] - 0s 100us/step - loss: 92.2891 - val_loss: 104.5458\n",
      "Epoch 250/500\n",
      "333/333 [==============================] - 0s 83us/step - loss: 96.0727 - val_loss: 107.6416\n",
      "Epoch 251/500\n",
      "333/333 [==============================] - 0s 87us/step - loss: 102.4918 - val_loss: 105.2907\n",
      "Epoch 252/500\n",
      "333/333 [==============================] - 0s 90us/step - loss: 106.3744 - val_loss: 92.0210\n",
      "Epoch 253/500\n",
      "333/333 [==============================] - 0s 92us/step - loss: 109.3460 - val_loss: 92.2374\n",
      "Epoch 254/500\n",
      "333/333 [==============================] - 0s 84us/step - loss: 91.3416 - val_loss: 107.8798\n",
      "Epoch 255/500\n",
      "333/333 [==============================] - 0s 85us/step - loss: 101.4879 - val_loss: 100.5137\n",
      "Epoch 256/500\n",
      "333/333 [==============================] - 0s 84us/step - loss: 98.8068 - val_loss: 102.3427\n",
      "Epoch 257/500\n",
      "333/333 [==============================] - 0s 86us/step - loss: 113.3834 - val_loss: 93.8698\n",
      "Epoch 258/500\n",
      "333/333 [==============================] - 0s 87us/step - loss: 104.6884 - val_loss: 82.6920\n",
      "Epoch 259/500\n",
      "333/333 [==============================] - 0s 87us/step - loss: 97.9705 - val_loss: 91.6879\n",
      "Epoch 260/500\n",
      "333/333 [==============================] - 0s 86us/step - loss: 97.8228 - val_loss: 95.3913\n",
      "Epoch 261/500\n",
      "333/333 [==============================] - 0s 92us/step - loss: 93.1098 - val_loss: 103.5095\n",
      "Epoch 262/500\n",
      "333/333 [==============================] - 0s 98us/step - loss: 93.0286 - val_loss: 95.2388\n",
      "Epoch 263/500\n",
      "333/333 [==============================] - 0s 101us/step - loss: 108.3929 - val_loss: 106.1865\n",
      "Epoch 264/500\n",
      "333/333 [==============================] - 0s 99us/step - loss: 104.5172 - val_loss: 51.1184\n",
      "Epoch 265/500\n",
      "333/333 [==============================] - 0s 105us/step - loss: 97.4037 - val_loss: 90.9012\n",
      "Epoch 266/500\n",
      "333/333 [==============================] - 0s 95us/step - loss: 101.6974 - val_loss: 85.2761\n",
      "Epoch 267/500\n",
      "333/333 [==============================] - 0s 88us/step - loss: 106.3767 - val_loss: 93.4083\n",
      "Epoch 268/500\n",
      "333/333 [==============================] - 0s 87us/step - loss: 99.1123 - val_loss: 73.0197\n",
      "Epoch 269/500\n",
      "333/333 [==============================] - 0s 143us/step - loss: 99.6968 - val_loss: 68.0465\n",
      "Epoch 270/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 95.5223 - val_loss: 79.3318\n",
      "Epoch 271/500\n",
      "333/333 [==============================] - 0s 178us/step - loss: 94.9991 - val_loss: 104.0679\n",
      "Epoch 272/500\n",
      "333/333 [==============================] - 0s 145us/step - loss: 88.8329 - val_loss: 87.9340\n",
      "Epoch 273/500\n",
      "333/333 [==============================] - 0s 201us/step - loss: 106.5638 - val_loss: 111.7284\n",
      "Epoch 274/500\n",
      "333/333 [==============================] - 0s 197us/step - loss: 95.1235 - val_loss: 75.9334\n",
      "Epoch 275/500\n",
      "333/333 [==============================] - 0s 180us/step - loss: 96.6252 - val_loss: 44.9658\n",
      "Epoch 276/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 113.7678 - val_loss: 75.8600\n",
      "Epoch 277/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 113.2712 - val_loss: 84.8092\n",
      "Epoch 278/500\n",
      "333/333 [==============================] - 0s 138us/step - loss: 94.9247 - val_loss: 98.0263\n",
      "Epoch 279/500\n",
      "333/333 [==============================] - 0s 135us/step - loss: 93.8226 - val_loss: 58.6777\n",
      "Epoch 280/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 106.9727 - val_loss: 89.7960\n",
      "Epoch 281/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 92.1930 - val_loss: 82.6806\n",
      "Epoch 282/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 103.4321 - val_loss: 66.0535\n",
      "Epoch 283/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 95.3211 - val_loss: 93.2006\n",
      "Epoch 284/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 104.2849 - val_loss: 98.1543\n",
      "Epoch 285/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 93.9702 - val_loss: 58.7358\n",
      "Epoch 286/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 81.0603 - val_loss: 70.2801\n",
      "Epoch 287/500\n",
      "333/333 [==============================] - 0s 104us/step - loss: 94.2166 - val_loss: 102.9582\n",
      "Epoch 288/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 102.7874 - val_loss: 52.5379\n",
      "Epoch 289/500\n",
      "333/333 [==============================] - 0s 102us/step - loss: 89.8998 - val_loss: 46.3844\n",
      "Epoch 290/500\n",
      "333/333 [==============================] - 0s 113us/step - loss: 98.6413 - val_loss: 99.2731\n",
      "Epoch 291/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 83.2103 - val_loss: 64.8614\n",
      "Epoch 292/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 84.0861 - val_loss: 51.2091\n",
      "Epoch 293/500\n",
      "333/333 [==============================] - 0s 113us/step - loss: 85.0829 - val_loss: 85.6541\n",
      "Epoch 294/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 79.1659 - val_loss: 59.4932\n",
      "Epoch 295/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 97.0590 - val_loss: 75.1678\n",
      "Epoch 296/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 85.5298 - val_loss: 57.7468\n",
      "Epoch 297/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 85.8294 - val_loss: 78.2156\n",
      "Epoch 298/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 107.9557 - val_loss: 85.6837\n",
      "Epoch 299/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 88.4360 - val_loss: 61.1135\n",
      "Epoch 300/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 80.0399 - val_loss: 70.0784\n",
      "Epoch 301/500\n",
      "333/333 [==============================] - 0s 91us/step - loss: 99.6826 - val_loss: 63.1103\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 0s 116us/step - loss: 76.1689 - val_loss: 57.3716\n",
      "Epoch 303/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 81.3937 - val_loss: 59.1259\n",
      "Epoch 304/500\n",
      "333/333 [==============================] - 0s 109us/step - loss: 84.6999 - val_loss: 85.1224\n",
      "Epoch 305/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 88.8873 - val_loss: 53.0967\n",
      "Epoch 306/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 95.9190 - val_loss: 56.6280\n",
      "Epoch 307/500\n",
      "333/333 [==============================] - 0s 101us/step - loss: 85.5900 - val_loss: 57.6423\n",
      "Epoch 308/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 87.1152 - val_loss: 59.7569\n",
      "Epoch 309/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 82.0683 - val_loss: 47.0995\n",
      "Epoch 310/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 80.2104 - val_loss: 53.5486\n",
      "Epoch 311/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 78.8328 - val_loss: 52.1513\n",
      "Epoch 312/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 90.6828 - val_loss: 59.5115\n",
      "Epoch 313/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 89.9936 - val_loss: 69.6676\n",
      "Epoch 314/500\n",
      "333/333 [==============================] - 0s 240us/step - loss: 85.7697 - val_loss: 55.9635\n",
      "Epoch 315/500\n",
      "333/333 [==============================] - 0s 145us/step - loss: 83.3046 - val_loss: 57.3821\n",
      "Epoch 316/500\n",
      "333/333 [==============================] - 0s 141us/step - loss: 80.3706 - val_loss: 51.3072\n",
      "Epoch 317/500\n",
      "333/333 [==============================] - 0s 117us/step - loss: 86.1544 - val_loss: 68.6510\n",
      "Epoch 318/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 82.0074 - val_loss: 61.8279\n",
      "Epoch 319/500\n",
      "333/333 [==============================] - 0s 153us/step - loss: 87.3734 - val_loss: 38.7492\n",
      "Epoch 320/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 90.7080 - val_loss: 77.8592\n",
      "Epoch 321/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 93.6158 - val_loss: 44.4580\n",
      "Epoch 322/500\n",
      "333/333 [==============================] - 0s 166us/step - loss: 79.7438 - val_loss: 52.7424\n",
      "Epoch 323/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 87.8474 - val_loss: 49.9158\n",
      "Epoch 324/500\n",
      "333/333 [==============================] - 0s 154us/step - loss: 82.0103 - val_loss: 58.1134\n",
      "Epoch 325/500\n",
      "333/333 [==============================] - 0s 173us/step - loss: 91.5890 - val_loss: 69.3741\n",
      "Epoch 326/500\n",
      "333/333 [==============================] - 0s 160us/step - loss: 85.6346 - val_loss: 55.4899\n",
      "Epoch 327/500\n",
      "333/333 [==============================] - 0s 144us/step - loss: 76.4087 - val_loss: 55.4436\n",
      "Epoch 328/500\n",
      "333/333 [==============================] - 0s 107us/step - loss: 81.9778 - val_loss: 40.0274\n",
      "Epoch 329/500\n",
      "333/333 [==============================] - 0s 164us/step - loss: 79.1936 - val_loss: 48.6037\n",
      "Epoch 330/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 81.0620 - val_loss: 64.0611\n",
      "Epoch 331/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 72.5493 - val_loss: 49.5785\n",
      "Epoch 332/500\n",
      "333/333 [==============================] - 0s 146us/step - loss: 85.0183 - val_loss: 39.7914\n",
      "Epoch 333/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 83.0202 - val_loss: 41.0249\n",
      "Epoch 334/500\n",
      "333/333 [==============================] - 0s 155us/step - loss: 79.7175 - val_loss: 41.1193\n",
      "Epoch 335/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 81.6946 - val_loss: 52.8433\n",
      "Epoch 336/500\n",
      "333/333 [==============================] - 0s 106us/step - loss: 86.1899 - val_loss: 56.0164\n",
      "Epoch 337/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 80.0793 - val_loss: 59.0968\n",
      "Epoch 338/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 83.5476 - val_loss: 40.6373\n",
      "Epoch 339/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 86.1959 - val_loss: 58.5030\n",
      "Epoch 340/500\n",
      "333/333 [==============================] - 0s 180us/step - loss: 83.7555 - val_loss: 63.9313\n",
      "Epoch 341/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 79.1178 - val_loss: 70.9512\n",
      "Epoch 342/500\n",
      "333/333 [==============================] - 0s 165us/step - loss: 75.7111 - val_loss: 59.7906\n",
      "Epoch 343/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 86.6149 - val_loss: 47.6696\n",
      "Epoch 344/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 79.6003 - val_loss: 30.1836\n",
      "Epoch 345/500\n",
      "333/333 [==============================] - 0s 157us/step - loss: 87.8047 - val_loss: 55.2400\n",
      "Epoch 346/500\n",
      "333/333 [==============================] - 0s 108us/step - loss: 81.8339 - val_loss: 91.8728\n",
      "Epoch 347/500\n",
      "333/333 [==============================] - 0s 113us/step - loss: 79.3716 - val_loss: 49.3605\n",
      "Epoch 348/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 69.7239 - val_loss: 39.9465\n",
      "Epoch 349/500\n",
      "333/333 [==============================] - 0s 135us/step - loss: 79.6737 - val_loss: 48.3809\n",
      "Epoch 350/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 94.4815 - val_loss: 72.3418\n",
      "Epoch 351/500\n",
      "333/333 [==============================] - 0s 148us/step - loss: 82.8669 - val_loss: 50.4201\n",
      "Epoch 352/500\n",
      "333/333 [==============================] - 0s 138us/step - loss: 85.0340 - val_loss: 52.9047\n",
      "Epoch 353/500\n",
      "333/333 [==============================] - 0s 153us/step - loss: 70.1617 - val_loss: 81.6550\n",
      "Epoch 354/500\n",
      "333/333 [==============================] - 0s 169us/step - loss: 75.6846 - val_loss: 62.2910\n",
      "Epoch 355/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 70.8028 - val_loss: 54.2204\n",
      "Epoch 356/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 75.5667 - val_loss: 50.9622\n",
      "Epoch 357/500\n",
      "333/333 [==============================] - 0s 163us/step - loss: 80.4837 - val_loss: 52.2122\n",
      "Epoch 358/500\n",
      "333/333 [==============================] - 0s 138us/step - loss: 81.8287 - val_loss: 58.3771\n",
      "Epoch 359/500\n",
      "333/333 [==============================] - 0s 112us/step - loss: 88.0811 - val_loss: 57.7355\n",
      "Epoch 360/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 77.3181 - val_loss: 58.2386\n",
      "Epoch 361/500\n",
      "333/333 [==============================] - 0s 103us/step - loss: 82.1028 - val_loss: 48.0660\n",
      "Epoch 362/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 65.0863 - val_loss: 43.4952\n",
      "Epoch 363/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 81.1559 - val_loss: 73.6985\n",
      "Epoch 364/500\n",
      "333/333 [==============================] - 0s 96us/step - loss: 73.1842 - val_loss: 80.2317\n",
      "Epoch 365/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 75.6247 - val_loss: 58.2257\n",
      "Epoch 366/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 72.3292 - val_loss: 46.1146\n",
      "Epoch 367/500\n",
      "333/333 [==============================] - 0s 164us/step - loss: 82.4493 - val_loss: 50.5944\n",
      "Epoch 368/500\n",
      "333/333 [==============================] - 0s 302us/step - loss: 76.7840 - val_loss: 48.7088\n",
      "Epoch 369/500\n",
      "333/333 [==============================] - 0s 197us/step - loss: 66.8006 - val_loss: 40.6404\n",
      "Epoch 370/500\n",
      "333/333 [==============================] - 0s 162us/step - loss: 75.2365 - val_loss: 43.6688\n",
      "Epoch 371/500\n",
      "333/333 [==============================] - 0s 194us/step - loss: 73.3879 - val_loss: 51.3336\n",
      "Epoch 372/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 83.3477 - val_loss: 63.1530\n",
      "Epoch 373/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 80.1163 - val_loss: 49.2383\n",
      "Epoch 374/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 75.1428 - val_loss: 46.7598\n",
      "Epoch 375/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 76.1643 - val_loss: 60.6322\n",
      "Epoch 376/500\n",
      "333/333 [==============================] - 0s 141us/step - loss: 82.6050 - val_loss: 41.8306\n",
      "Epoch 377/500\n",
      "333/333 [==============================] - 0s 107us/step - loss: 81.3595 - val_loss: 51.5529\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 0s 112us/step - loss: 87.0969 - val_loss: 77.8368\n",
      "Epoch 379/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 73.4716 - val_loss: 67.1944\n",
      "Epoch 380/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 76.4787 - val_loss: 54.8494\n",
      "Epoch 381/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 74.9432 - val_loss: 52.0453\n",
      "Epoch 382/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 79.8110 - val_loss: 55.0853\n",
      "Epoch 383/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 82.7560 - val_loss: 62.2050\n",
      "Epoch 384/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 79.1062 - val_loss: 43.9512\n",
      "Epoch 385/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 66.0756 - val_loss: 41.3808\n",
      "Epoch 386/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 82.5816 - val_loss: 55.6083\n",
      "Epoch 387/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 77.9147 - val_loss: 61.6811\n",
      "Epoch 388/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 73.3867 - val_loss: 60.4702\n",
      "Epoch 389/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 83.7309 - val_loss: 52.8269\n",
      "Epoch 390/500\n",
      "333/333 [==============================] - 0s 140us/step - loss: 76.3076 - val_loss: 45.6993\n",
      "Epoch 391/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 78.9892 - val_loss: 52.4582\n",
      "Epoch 392/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 80.5610 - val_loss: 46.2631\n",
      "Epoch 393/500\n",
      "333/333 [==============================] - 0s 140us/step - loss: 69.4455 - val_loss: 43.7271\n",
      "Epoch 394/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 74.4437 - val_loss: 39.1977\n",
      "Epoch 395/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 77.4590 - val_loss: 81.6989\n",
      "Epoch 396/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 78.5451 - val_loss: 66.7472\n",
      "Epoch 397/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 71.8137 - val_loss: 54.1460\n",
      "Epoch 398/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 77.3439 - val_loss: 40.9206\n",
      "Epoch 399/500\n",
      "333/333 [==============================] - 0s 154us/step - loss: 81.9183 - val_loss: 55.7043\n",
      "Epoch 400/500\n",
      "333/333 [==============================] - 0s 137us/step - loss: 85.5787 - val_loss: 52.9492\n",
      "Epoch 401/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 76.9051 - val_loss: 57.8202\n",
      "Epoch 402/500\n",
      "333/333 [==============================] - 0s 130us/step - loss: 71.7445 - val_loss: 44.9137\n",
      "Epoch 403/500\n",
      "333/333 [==============================] - 0s 143us/step - loss: 78.7039 - val_loss: 33.7783\n",
      "Epoch 404/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 76.0580 - val_loss: 42.9062\n",
      "Epoch 405/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 77.9501 - val_loss: 41.9104\n",
      "Epoch 406/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 66.0301 - val_loss: 49.8388\n",
      "Epoch 407/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 65.5213 - val_loss: 44.4408\n",
      "Epoch 408/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 74.8305 - val_loss: 59.4366\n",
      "Epoch 409/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 78.4935 - val_loss: 56.9408\n",
      "Epoch 410/500\n",
      "333/333 [==============================] - 0s 97us/step - loss: 75.0520 - val_loss: 50.0981\n",
      "Epoch 411/500\n",
      "333/333 [==============================] - 0s 88us/step - loss: 66.4418 - val_loss: 40.7160\n",
      "Epoch 412/500\n",
      "333/333 [==============================] - 0s 94us/step - loss: 73.0819 - val_loss: 72.0941\n",
      "Epoch 413/500\n",
      "333/333 [==============================] - 0s 86us/step - loss: 68.2159 - val_loss: 59.8718\n",
      "Epoch 414/500\n",
      "333/333 [==============================] - 0s 97us/step - loss: 76.5467 - val_loss: 34.7397\n",
      "Epoch 415/500\n",
      "333/333 [==============================] - 0s 89us/step - loss: 75.3645 - val_loss: 52.9692\n",
      "Epoch 416/500\n",
      "333/333 [==============================] - 0s 90us/step - loss: 75.4593 - val_loss: 63.8255\n",
      "Epoch 417/500\n",
      "333/333 [==============================] - 0s 90us/step - loss: 76.2007 - val_loss: 37.9673\n",
      "Epoch 418/500\n",
      "333/333 [==============================] - 0s 96us/step - loss: 62.0469 - val_loss: 44.2821\n",
      "Epoch 419/500\n",
      "333/333 [==============================] - 0s 93us/step - loss: 84.4798 - val_loss: 69.0043\n",
      "Epoch 420/500\n",
      "333/333 [==============================] - 0s 100us/step - loss: 61.6101 - val_loss: 50.8095\n",
      "Epoch 421/500\n",
      "333/333 [==============================] - 0s 99us/step - loss: 65.5936 - val_loss: 48.1249\n",
      "Epoch 422/500\n",
      "333/333 [==============================] - 0s 100us/step - loss: 81.4542 - val_loss: 52.1857\n",
      "Epoch 423/500\n",
      "333/333 [==============================] - 0s 96us/step - loss: 65.5451 - val_loss: 54.2943\n",
      "Epoch 424/500\n",
      "333/333 [==============================] - 0s 108us/step - loss: 82.2226 - val_loss: 45.6643\n",
      "Epoch 425/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 83.3331 - val_loss: 31.3229\n",
      "Epoch 426/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 71.7568 - val_loss: 50.4520\n",
      "Epoch 427/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 69.5428 - val_loss: 56.4265\n",
      "Epoch 428/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 72.3799 - val_loss: 29.2692\n",
      "Epoch 429/500\n",
      "333/333 [==============================] - 0s 112us/step - loss: 63.0394 - val_loss: 37.4618\n",
      "Epoch 430/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 72.6960 - val_loss: 44.6322\n",
      "Epoch 431/500\n",
      "333/333 [==============================] - 0s 119us/step - loss: 66.9519 - val_loss: 39.1664\n",
      "Epoch 432/500\n",
      "333/333 [==============================] - 0s 108us/step - loss: 75.2666 - val_loss: 61.6591\n",
      "Epoch 433/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 76.0182 - val_loss: 41.9042\n",
      "Epoch 434/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 71.4067 - val_loss: 32.9962\n",
      "Epoch 435/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 75.4382 - val_loss: 55.0502\n",
      "Epoch 436/500\n",
      "333/333 [==============================] - 0s 120us/step - loss: 81.2186 - val_loss: 51.9651\n",
      "Epoch 437/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 88.1620 - val_loss: 40.7778\n",
      "Epoch 438/500\n",
      "333/333 [==============================] - 0s 104us/step - loss: 72.6035 - val_loss: 66.3868\n",
      "Epoch 439/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 64.1499 - val_loss: 54.2485\n",
      "Epoch 440/500\n",
      "333/333 [==============================] - 0s 148us/step - loss: 76.6265 - val_loss: 44.7892\n",
      "Epoch 441/500\n",
      "333/333 [==============================] - 0s 141us/step - loss: 75.8512 - val_loss: 52.7440\n",
      "Epoch 442/500\n",
      "333/333 [==============================] - 0s 138us/step - loss: 69.8435 - val_loss: 37.3535\n",
      "Epoch 443/500\n",
      "333/333 [==============================] - 0s 150us/step - loss: 66.5423 - val_loss: 35.8401\n",
      "Epoch 444/500\n",
      "333/333 [==============================] - 0s 128us/step - loss: 63.6323 - val_loss: 48.0921\n",
      "Epoch 445/500\n",
      "333/333 [==============================] - 0s 159us/step - loss: 68.3686 - val_loss: 30.6446\n",
      "Epoch 446/500\n",
      "333/333 [==============================] - 0s 147us/step - loss: 73.9145 - val_loss: 42.0101\n",
      "Epoch 447/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 71.8952 - val_loss: 56.0219\n",
      "Epoch 448/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 70.9040 - val_loss: 43.0776\n",
      "Epoch 449/500\n",
      "333/333 [==============================] - 0s 114us/step - loss: 75.6962 - val_loss: 38.8905\n",
      "Epoch 450/500\n",
      "333/333 [==============================] - 0s 126us/step - loss: 77.0678 - val_loss: 36.8473\n",
      "Epoch 451/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 74.3911 - val_loss: 44.3354\n",
      "Epoch 452/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 70.8729 - val_loss: 50.8186\n",
      "Epoch 453/500\n",
      "333/333 [==============================] - 0s 135us/step - loss: 64.2601 - val_loss: 45.4067\n",
      "Epoch 454/500\n",
      "333/333 [==============================] - 0s 145us/step - loss: 71.5788 - val_loss: 43.7684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 65.4308 - val_loss: 40.9443\n",
      "Epoch 456/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 69.2589 - val_loss: 62.4322\n",
      "Epoch 457/500\n",
      "333/333 [==============================] - 0s 127us/step - loss: 76.5772 - val_loss: 49.3044\n",
      "Epoch 458/500\n",
      "333/333 [==============================] - 0s 144us/step - loss: 69.1029 - val_loss: 26.1296\n",
      "Epoch 459/500\n",
      "333/333 [==============================] - 0s 136us/step - loss: 82.4756 - val_loss: 54.5717\n",
      "Epoch 460/500\n",
      "333/333 [==============================] - 0s 124us/step - loss: 68.5095 - val_loss: 68.2503\n",
      "Epoch 461/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 72.0612 - val_loss: 51.9829\n",
      "Epoch 462/500\n",
      "333/333 [==============================] - 0s 149us/step - loss: 73.7156 - val_loss: 31.3080\n",
      "Epoch 463/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 77.1235 - val_loss: 46.7395\n",
      "Epoch 464/500\n",
      "333/333 [==============================] - 0s 133us/step - loss: 72.8247 - val_loss: 50.1021\n",
      "Epoch 465/500\n",
      "333/333 [==============================] - 0s 115us/step - loss: 69.9793 - val_loss: 34.2496\n",
      "Epoch 466/500\n",
      "333/333 [==============================] - 0s 116us/step - loss: 72.9784 - val_loss: 43.6039\n",
      "Epoch 467/500\n",
      "333/333 [==============================] - 0s 110us/step - loss: 69.3208 - val_loss: 51.9889\n",
      "Epoch 468/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 67.5015 - val_loss: 46.8027\n",
      "Epoch 469/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 66.3618 - val_loss: 36.1902\n",
      "Epoch 470/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 69.1869 - val_loss: 48.9788\n",
      "Epoch 471/500\n",
      "333/333 [==============================] - 0s 145us/step - loss: 75.3217 - val_loss: 48.3121\n",
      "Epoch 472/500\n",
      "333/333 [==============================] - 0s 134us/step - loss: 64.7962 - val_loss: 58.5645\n",
      "Epoch 473/500\n",
      "333/333 [==============================] - 0s 111us/step - loss: 77.3047 - val_loss: 64.6581\n",
      "Epoch 474/500\n",
      "333/333 [==============================] - 0s 132us/step - loss: 68.6109 - val_loss: 54.2306\n",
      "Epoch 475/500\n",
      "333/333 [==============================] - 0s 141us/step - loss: 72.0831 - val_loss: 39.8596\n",
      "Epoch 476/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 68.9387 - val_loss: 46.3540\n",
      "Epoch 477/500\n",
      "333/333 [==============================] - 0s 144us/step - loss: 64.9210 - val_loss: 47.1120\n",
      "Epoch 478/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 69.8681 - val_loss: 32.1116\n",
      "Epoch 479/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 65.1291 - val_loss: 52.2234\n",
      "Epoch 480/500\n",
      "333/333 [==============================] - 0s 133us/step - loss: 71.4814 - val_loss: 52.2477\n",
      "Epoch 481/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 76.7760 - val_loss: 30.2958\n",
      "Epoch 482/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 66.1539 - val_loss: 57.8228\n",
      "Epoch 483/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 64.7765 - val_loss: 42.0169\n",
      "Epoch 484/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 73.4507 - val_loss: 49.8767\n",
      "Epoch 485/500\n",
      "333/333 [==============================] - 0s 117us/step - loss: 66.1334 - val_loss: 40.9741\n",
      "Epoch 486/500\n",
      "333/333 [==============================] - 0s 123us/step - loss: 72.4656 - val_loss: 53.7466\n",
      "Epoch 487/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 70.7186 - val_loss: 40.5870\n",
      "Epoch 488/500\n",
      "333/333 [==============================] - 0s 125us/step - loss: 70.8783 - val_loss: 26.3487\n",
      "Epoch 489/500\n",
      "333/333 [==============================] - 0s 113us/step - loss: 62.6643 - val_loss: 39.1690\n",
      "Epoch 490/500\n",
      "333/333 [==============================] - 0s 121us/step - loss: 76.8996 - val_loss: 42.3041\n",
      "Epoch 491/500\n",
      "333/333 [==============================] - 0s 117us/step - loss: 69.8734 - val_loss: 52.6722\n",
      "Epoch 492/500\n",
      "333/333 [==============================] - 0s 133us/step - loss: 64.0545 - val_loss: 33.0385\n",
      "Epoch 493/500\n",
      "333/333 [==============================] - 0s 139us/step - loss: 71.1978 - val_loss: 27.2879\n",
      "Epoch 494/500\n",
      "333/333 [==============================] - 0s 109us/step - loss: 73.5262 - val_loss: 35.4897\n",
      "Epoch 495/500\n",
      "333/333 [==============================] - 0s 122us/step - loss: 69.3988 - val_loss: 54.2985\n",
      "Epoch 496/500\n",
      "333/333 [==============================] - 0s 129us/step - loss: 70.8395 - val_loss: 45.0806\n",
      "Epoch 497/500\n",
      "333/333 [==============================] - 0s 140us/step - loss: 62.8456 - val_loss: 38.1692\n",
      "Epoch 498/500\n",
      "333/333 [==============================] - 0s 131us/step - loss: 64.7496 - val_loss: 34.8488\n",
      "Epoch 499/500\n",
      "333/333 [==============================] - 0s 133us/step - loss: 63.9750 - val_loss: 46.4350\n",
      "Epoch 500/500\n",
      "333/333 [==============================] - 0s 143us/step - loss: 70.9456 - val_loss: 47.8311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocess', ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('standard', StandardScaler(copy=True, with_mean=True, with_std=True), ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin']), ('encoding', OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>), ['car name'])])), ('reg', <keras.wrappers.scikit_learn.KerasRegressor object at 0x1a291cab70>)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3021</td>\n",
       "      <td>16.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement  horsepower  weight  acceleration  model year  \\\n",
       "100          6         250.0          88    3021          16.5          73   \n",
       "\n",
       "     origin       car name  \n",
       "100       1  ford maverick  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X[X.index==100]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3021</td>\n",
       "      <td>16.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "100  18.0          6         250.0          88    3021          16.5   \n",
       "\n",
       "     model year  origin       car name  \n",
       "100          73       1  ford maverick  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1.index==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshay/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(15.478943, dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 291us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshay/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.066057427984152"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, mod.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
