{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Retrieval using AlexNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals :\n",
    "- Create AlexNet architecture using Pre-Trained Weights\n",
    "- Create Image Embeddings using Transfer Learning \n",
    "- Create Nearest Neighbour Algorithm \n",
    "- Give a query iamges, retrieve similar images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import random\n",
    "from scipy import ndimage\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "%matplotlib inline\n",
    "print('Tensorflow version : {0}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AlexNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AlexNet](./images/alexnet_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Weights from Michael Guerzhoy and Davi Frossard\n",
    " [http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Pre-Trained Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the numpy weights\n",
    "alexnet_path = op.join(op.curdir, 'processed','bvlc_alexnet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read weights in numpy\n",
    "variable_data = np.load(alexnet_path, encoding='bytes').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable_data is a dictionary\n",
    "type(variable_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fc6', 'fc7', 'fc8', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys\n",
    "variable_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 3, 96)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "# Convolution layer - 1 weights\n",
    "conv1_preW = variable_data[\"conv1\"][0]\n",
    "conv1_preb = variable_data[\"conv1\"][1]\n",
    "print(conv1_preW.shape)\n",
    "print(conv1_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 48, 256)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "# Convolution layer - 2 weights\n",
    "conv2_preW = variable_data[\"conv2\"][0]\n",
    "conv2_preb = variable_data[\"conv2\"][1]\n",
    "print(conv2_preW.shape)\n",
    "print(conv2_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 256, 384)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "# Convolution layer-3 weights\n",
    "conv3_preW = variable_data[\"conv3\"][0]\n",
    "conv3_preb = variable_data[\"conv3\"][1]\n",
    "print(conv3_preW.shape)\n",
    "print(conv3_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 192, 384)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "# Convolution layer-4 weights\n",
    "conv4_preW = variable_data[\"conv4\"][0]\n",
    "conv4_preb = variable_data[\"conv4\"][1]\n",
    "print(conv4_preW.shape)\n",
    "print(conv4_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 192, 256)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "# Convolution layer-5 weights\n",
    "conv5_preW = variable_data[\"conv5\"][0]\n",
    "conv5_preb = variable_data[\"conv5\"][1]\n",
    "print(conv5_preW.shape)\n",
    "print(conv5_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 4096)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "# Fully contected layer - 1\n",
    "fc6_preW = variable_data[\"fc6\"][0]\n",
    "fc6_preb = variable_data[\"fc6\"][1]\n",
    "print(fc6_preW.shape)\n",
    "print(fc6_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 4096)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "# Fully connected layer -2 \n",
    "fc7_preW = variable_data[\"fc7\"][0]\n",
    "fc7_preb = variable_data[\"fc7\"][1]\n",
    "print(fc7_preW.shape)\n",
    "print(fc7_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1000)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Fully connected layer - 3\n",
    "fc8_preW = variable_data[\"fc8\"][0]\n",
    "fc8_preb = variable_data[\"fc8\"][1]\n",
    "print(fc8_preW.shape)\n",
    "print(fc8_preb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the AlexNet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixel_depth = 255.0\n",
    "resized_height = 227\n",
    "resized_width = 227\n",
    "num_channels = 3\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(tf.uint8, [None, None, None, num_channels],\n",
    "                       name='input')\n",
    "    \n",
    "    to_float = tf.cast(x, tf.float32)\n",
    "    resized = tf.image.resize_images(to_float, (resized_height, resized_width))\n",
    "    \n",
    "    # Convolution 1\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        kernel = tf.Variable(conv1_preW, name='weights')\n",
    "        biases = tf.Variable(conv1_preb, name='biases')\n",
    "        conv = tf.nn.conv2d(resized, kernel, [1, 4, 4, 1], padding=\"SAME\")\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "    # Local response normalization 2\n",
    "    radius = 2\n",
    "    alpha = 2e-05\n",
    "    beta = 0.75\n",
    "    bias = 1.0\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1,\n",
    "                                              depth_radius=radius,\n",
    "                                              alpha=alpha,\n",
    "                                              beta=beta,\n",
    "                                              bias=bias)\n",
    "\n",
    "    # Maxpool 1\n",
    "    pool1 = tf.nn.max_pool(lrn1,\n",
    "                           ksize=[1, 3, 3, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='VALID',\n",
    "                           name='pool1')\n",
    "\n",
    "    # Convolution 2\n",
    "    with tf.name_scope('conv2') as scope:\n",
    "\n",
    "        kernel = tf.Variable(conv2_preW, name='weights')\n",
    "        biases = tf.Variable(conv2_preb, name='biases')\n",
    "\n",
    "        input_a, input_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                    value=pool1)\n",
    "        kernel_a, kernel_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                      value=kernel)\n",
    "\n",
    "        with tf.name_scope('A'):\n",
    "            conv_a = tf.nn.conv2d(input_a, kernel_a, [1, 1, 1, 1], padding=\"SAME\")        \n",
    "\n",
    "        with tf.name_scope('B'):\n",
    "            conv_b = tf.nn.conv2d(input_b, kernel_b, [1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "        conv = tf.concat(values=[conv_a, conv_b], axis=3)\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "    # Local response normalization 2\n",
    "    radius = 2\n",
    "    alpha = 2e-05\n",
    "    beta = 0.75\n",
    "    bias = 1.0\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2,\n",
    "                                              depth_radius=radius,\n",
    "                                              alpha=alpha,\n",
    "                                              beta=beta,\n",
    "                                              bias=bias)\n",
    "\n",
    "    # Maxpool 2\n",
    "    pool2 = tf.nn.max_pool(lrn2,\n",
    "                           ksize=[1, 3, 3, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='VALID',\n",
    "                           name='pool2')\n",
    "\n",
    "    with tf.name_scope('conv3') as scope:\n",
    "        kernel = tf.Variable(conv3_preW, name='weights')\n",
    "        biases = tf.Variable(conv3_preb, name='biases')\n",
    "        conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding=\"SAME\")\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv3 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "\n",
    "    with tf.name_scope('conv4') as scope:\n",
    "\n",
    "        kernel = tf.Variable(conv4_preW, name='weights')\n",
    "        biases = tf.Variable(conv4_preb, name='biases')\n",
    "\n",
    "        input_a, input_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                    value=conv3)\n",
    "        kernel_a, kernel_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                      value=kernel)\n",
    "\n",
    "        with tf.name_scope('A'):\n",
    "            conv_a = tf.nn.conv2d(input_a, kernel_a, [1, 1, 1, 1], padding=\"SAME\")        \n",
    "\n",
    "        with tf.name_scope('B'):\n",
    "            conv_b = tf.nn.conv2d(input_b, kernel_b, [1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "        conv = tf.concat(values=[conv_a, conv_b], axis=3)\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv4 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "\n",
    "    with tf.name_scope('conv5') as scope:\n",
    "\n",
    "        kernel = tf.Variable(conv5_preW, name='weights')\n",
    "        biases = tf.Variable(conv5_preb, name='biases')\n",
    "\n",
    "        input_a, input_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                    value=conv4)\n",
    "        kernel_a, kernel_b = tf.split(axis=3,\n",
    "                                      num_or_size_splits=2,\n",
    "                                      value=kernel)\n",
    "\n",
    "        with tf.name_scope('A'):\n",
    "            conv_a = tf.nn.conv2d(input_a, kernel_a, [1, 1, 1, 1], padding=\"SAME\")        \n",
    "\n",
    "        with tf.name_scope('B'):\n",
    "            conv_b = tf.nn.conv2d(input_b, kernel_b, [1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "        conv = tf.concat(values=[conv_a, conv_b],axis=3)\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv5 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "\n",
    "    # Maxpool 2\n",
    "    pool5 = tf.nn.max_pool(conv5,\n",
    "                           ksize=[1, 3, 3, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='VALID',\n",
    "                           name='pool5')\n",
    "\n",
    "    # Fully connected 6\n",
    "    with tf.name_scope('fc6'):\n",
    "        weights = tf.Variable(fc6_preW, name='fc6_weights')\n",
    "        bias = tf.Variable(fc6_preb, name='fc6_bias')\n",
    "        shape = tf.shape(pool5)\n",
    "        size = shape[1] * shape[2] * shape[3]\n",
    "        fc6 = tf.nn.relu_layer(tf.reshape(pool5, [-1, size]),\n",
    "                               weights, bias, name='relu')\n",
    "\n",
    "    # Fully connected 7\n",
    "    with tf.name_scope('fc7'):\n",
    "        weights = tf.Variable(fc7_preW, name='weights')\n",
    "        bias = tf.Variable(fc7_preb, name='bias')\n",
    "        fc7 = tf.nn.relu_layer(fc6, weights, bias, name='relu')\n",
    "\n",
    "    # Fully connected 8\n",
    "    with tf.name_scope('fc8'):\n",
    "        weights = tf.Variable(fc8_preW, name='weights')\n",
    "        bias = tf.Variable(fc8_preb, name='bias')\n",
    "        # fc8 = tf.matmul(fc7, weights) + bias\n",
    "        fc8 = tf.nn.xw_plus_b(fc7, weights, bias)\n",
    "\n",
    "    softmax = tf.nn.softmax(fc8)\n",
    "\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize alexnet graph\n",
    "sess = tf.Session(graph=graph)\n",
    "sess.run(init)\n",
    "\n",
    "writer = tf.summary.FileWriter('tensorboard/alexnet', graph=graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir='tensorboard/alexnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export AlexNet Model ( Graph + Weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    alex_vars_path = op.join(op.curdir, 'saved_models','alex_vars')\n",
    "    save_path = saver.save(sess, alex_vars_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Graph and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_models/alex_vars\n"
     ]
    }
   ],
   "source": [
    "alex_vars_path = op.join(op.curdir, 'saved_models','alex_vars')\n",
    "alex_meta_file_path = op.join(op.curdir, 'saved_models','alex_vars.meta')\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    importer = tf.train.import_meta_graph(alex_meta_file_path)\n",
    "\n",
    "sess = tf.Session(graph=graph)\n",
    "importer.restore(sess, alex_vars_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'input' type=Placeholder>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'size' type=Const>,\n",
       " <tf.Operation 'ResizeBilinear' type=ResizeBilinear>,\n",
       " <tf.Operation 'conv1/weights/initial_value' type=Const>,\n",
       " <tf.Operation 'conv1/weights' type=VariableV2>,\n",
       " <tf.Operation 'conv1/weights/Assign' type=Assign>,\n",
       " <tf.Operation 'conv1/weights/read' type=Identity>,\n",
       " <tf.Operation 'conv1/biases/initial_value' type=Const>,\n",
       " <tf.Operation 'conv1/biases' type=VariableV2>,\n",
       " <tf.Operation 'conv1/biases/Assign' type=Assign>,\n",
       " <tf.Operation 'conv1/biases/read' type=Identity>,\n",
       " <tf.Operation 'conv1/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv1' type=Relu>,\n",
       " <tf.Operation 'LRN' type=LRN>,\n",
       " <tf.Operation 'pool1' type=MaxPool>,\n",
       " <tf.Operation 'conv2/weights/initial_value' type=Const>,\n",
       " <tf.Operation 'conv2/weights' type=VariableV2>,\n",
       " <tf.Operation 'conv2/weights/Assign' type=Assign>,\n",
       " <tf.Operation 'conv2/weights/read' type=Identity>,\n",
       " <tf.Operation 'conv2/biases/initial_value' type=Const>,\n",
       " <tf.Operation 'conv2/biases' type=VariableV2>,\n",
       " <tf.Operation 'conv2/biases/Assign' type=Assign>,\n",
       " <tf.Operation 'conv2/biases/read' type=Identity>,\n",
       " <tf.Operation 'conv2/Const' type=Const>,\n",
       " <tf.Operation 'conv2/split/split_dim' type=Const>,\n",
       " <tf.Operation 'conv2/split' type=Split>,\n",
       " <tf.Operation 'conv2/Const_1' type=Const>,\n",
       " <tf.Operation 'conv2/split_1/split_dim' type=Const>,\n",
       " <tf.Operation 'conv2/split_1' type=Split>,\n",
       " <tf.Operation 'conv2/A/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2/B/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2/concat/axis' type=Const>,\n",
       " <tf.Operation 'conv2/concat' type=ConcatV2>,\n",
       " <tf.Operation 'conv2/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2' type=Relu>,\n",
       " <tf.Operation 'LRN_1' type=LRN>,\n",
       " <tf.Operation 'pool2' type=MaxPool>,\n",
       " <tf.Operation 'conv3/weights/initial_value' type=Const>,\n",
       " <tf.Operation 'conv3/weights' type=VariableV2>,\n",
       " <tf.Operation 'conv3/weights/Assign' type=Assign>,\n",
       " <tf.Operation 'conv3/weights/read' type=Identity>,\n",
       " <tf.Operation 'conv3/biases/initial_value' type=Const>,\n",
       " <tf.Operation 'conv3/biases' type=VariableV2>,\n",
       " <tf.Operation 'conv3/biases/Assign' type=Assign>,\n",
       " <tf.Operation 'conv3/biases/read' type=Identity>,\n",
       " <tf.Operation 'conv3/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv3/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv3' type=Relu>,\n",
       " <tf.Operation 'conv4/weights/initial_value' type=Const>,\n",
       " <tf.Operation 'conv4/weights' type=VariableV2>,\n",
       " <tf.Operation 'conv4/weights/Assign' type=Assign>,\n",
       " <tf.Operation 'conv4/weights/read' type=Identity>,\n",
       " <tf.Operation 'conv4/biases/initial_value' type=Const>,\n",
       " <tf.Operation 'conv4/biases' type=VariableV2>,\n",
       " <tf.Operation 'conv4/biases/Assign' type=Assign>,\n",
       " <tf.Operation 'conv4/biases/read' type=Identity>,\n",
       " <tf.Operation 'conv4/Const' type=Const>,\n",
       " <tf.Operation 'conv4/split/split_dim' type=Const>,\n",
       " <tf.Operation 'conv4/split' type=Split>,\n",
       " <tf.Operation 'conv4/Const_1' type=Const>,\n",
       " <tf.Operation 'conv4/split_1/split_dim' type=Const>,\n",
       " <tf.Operation 'conv4/split_1' type=Split>,\n",
       " <tf.Operation 'conv4/A/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv4/B/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv4/concat/axis' type=Const>,\n",
       " <tf.Operation 'conv4/concat' type=ConcatV2>,\n",
       " <tf.Operation 'conv4/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv4' type=Relu>,\n",
       " <tf.Operation 'conv5/weights/initial_value' type=Const>,\n",
       " <tf.Operation 'conv5/weights' type=VariableV2>,\n",
       " <tf.Operation 'conv5/weights/Assign' type=Assign>,\n",
       " <tf.Operation 'conv5/weights/read' type=Identity>,\n",
       " <tf.Operation 'conv5/biases/initial_value' type=Const>,\n",
       " <tf.Operation 'conv5/biases' type=VariableV2>,\n",
       " <tf.Operation 'conv5/biases/Assign' type=Assign>,\n",
       " <tf.Operation 'conv5/biases/read' type=Identity>,\n",
       " <tf.Operation 'conv5/Const' type=Const>,\n",
       " <tf.Operation 'conv5/split/split_dim' type=Const>,\n",
       " <tf.Operation 'conv5/split' type=Split>,\n",
       " <tf.Operation 'conv5/Const_1' type=Const>,\n",
       " <tf.Operation 'conv5/split_1/split_dim' type=Const>,\n",
       " <tf.Operation 'conv5/split_1' type=Split>,\n",
       " <tf.Operation 'conv5/A/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv5/B/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv5/concat/axis' type=Const>,\n",
       " <tf.Operation 'conv5/concat' type=ConcatV2>,\n",
       " <tf.Operation 'conv5/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv5' type=Relu>,\n",
       " <tf.Operation 'pool5' type=MaxPool>,\n",
       " <tf.Operation 'fc6/fc6_weights/initial_value' type=Const>,\n",
       " <tf.Operation 'fc6/fc6_weights' type=VariableV2>,\n",
       " <tf.Operation 'fc6/fc6_weights/Assign' type=Assign>,\n",
       " <tf.Operation 'fc6/fc6_weights/read' type=Identity>,\n",
       " <tf.Operation 'fc6/fc6_bias/initial_value' type=Const>,\n",
       " <tf.Operation 'fc6/fc6_bias' type=VariableV2>,\n",
       " <tf.Operation 'fc6/fc6_bias/Assign' type=Assign>,\n",
       " <tf.Operation 'fc6/fc6_bias/read' type=Identity>,\n",
       " <tf.Operation 'fc6/Shape' type=Shape>,\n",
       " <tf.Operation 'fc6/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'fc6/strided_slice_1/stack' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice_1/stack_1' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice_1/stack_2' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice_1' type=StridedSlice>,\n",
       " <tf.Operation 'fc6/mul' type=Mul>,\n",
       " <tf.Operation 'fc6/strided_slice_2/stack' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice_2/stack_1' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice_2/stack_2' type=Const>,\n",
       " <tf.Operation 'fc6/strided_slice_2' type=StridedSlice>,\n",
       " <tf.Operation 'fc6/mul_1' type=Mul>,\n",
       " <tf.Operation 'fc6/Reshape/shape/0' type=Const>,\n",
       " <tf.Operation 'fc6/Reshape/shape' type=Pack>,\n",
       " <tf.Operation 'fc6/Reshape' type=Reshape>,\n",
       " <tf.Operation 'fc6/relu/MatMul' type=MatMul>,\n",
       " <tf.Operation 'fc6/relu/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'fc6/relu' type=Relu>,\n",
       " <tf.Operation 'fc7/weights/initial_value' type=Const>,\n",
       " <tf.Operation 'fc7/weights' type=VariableV2>,\n",
       " <tf.Operation 'fc7/weights/Assign' type=Assign>,\n",
       " <tf.Operation 'fc7/weights/read' type=Identity>,\n",
       " <tf.Operation 'fc7/bias/initial_value' type=Const>,\n",
       " <tf.Operation 'fc7/bias' type=VariableV2>,\n",
       " <tf.Operation 'fc7/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'fc7/bias/read' type=Identity>,\n",
       " <tf.Operation 'fc7/relu/MatMul' type=MatMul>,\n",
       " <tf.Operation 'fc7/relu/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'fc7/relu' type=Relu>,\n",
       " <tf.Operation 'fc8/weights/initial_value' type=Const>,\n",
       " <tf.Operation 'fc8/weights' type=VariableV2>,\n",
       " <tf.Operation 'fc8/weights/Assign' type=Assign>,\n",
       " <tf.Operation 'fc8/weights/read' type=Identity>,\n",
       " <tf.Operation 'fc8/bias/initial_value' type=Const>,\n",
       " <tf.Operation 'fc8/bias' type=VariableV2>,\n",
       " <tf.Operation 'fc8/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'fc8/bias/read' type=Identity>,\n",
       " <tf.Operation 'fc8/xw_plus_b/MatMul' type=MatMul>,\n",
       " <tf.Operation 'fc8/xw_plus_b' type=BiasAdd>,\n",
       " <tf.Operation 'Softmax' type=Softmax>,\n",
       " <tf.Operation 'init' type=NoOp>,\n",
       " <tf.Operation 'save/Const' type=Const>,\n",
       " <tf.Operation 'save/SaveV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/SaveV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/SaveV2' type=SaveV2>,\n",
       " <tf.Operation 'save/control_dependency' type=Identity>,\n",
       " <tf.Operation 'save/RestoreV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_1/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_1/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_1' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_1' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_2' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_2' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_3/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_3/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_3' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_3' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_4/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_4/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_4' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_4' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_5/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_5/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_5' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_5' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_6/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_6/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_6' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_6' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_7/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_7/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_7' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_7' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_8/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_8/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_8' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_8' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_9/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_9/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_9' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_9' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_10/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_10/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_10' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_10' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_11/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_11/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_11' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_11' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_12/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_12/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_12' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_12' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_13/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_13/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_13' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_13' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_14/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_14/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_14' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_14' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_15/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_15/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_15' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_15' type=Assign>,\n",
       " <tf.Operation 'save/restore_all' type=NoOp>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract fc7 output\n",
    "fc7_op = graph.get_operation_by_name('fc7/relu')\n",
    "fc7 = fc7_op.outputs[0]\n",
    "x = graph.get_operation_by_name('input').outputs[0]\n",
    "init = graph.get_operation_by_name('init')\n",
    "\n",
    "sess = tf.Session(graph=graph)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embedding size : 4096\n"
     ]
    }
   ],
   "source": [
    "image_embedding_size = fc7.get_shape()[1]\n",
    "print('Image embedding size : {0}'.format(image_embedding_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Image Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50066"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UTZap50K\n",
    "UTZap50K_directory = op.join(op.curdir, 'processed','utzap50k')\n",
    "\n",
    "all_files = [y for x in os.walk(UTZap50K_directory) for y in glob(os.path.join(x[0], '*.jpg'))]\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./processed/utzap50k/ut-zap50k-images-square/Boots/Ankle/A. Testoni/7965307.5291.jpg',\n",
       " './processed/utzap50k/ut-zap50k-images-square/Boots/Ankle/A. Testoni/7999255.363731.jpg',\n",
       " './processed/utzap50k/ut-zap50k-images-square/Boots/Ankle/A. Testoni/8000978.364150.jpg',\n",
       " './processed/utzap50k/ut-zap50k-images-square/Boots/Ankle/adidas/8030969.3.jpg',\n",
       " './processed/utzap50k/ut-zap50k-images-square/Boots/Ankle/adidas/8030970.107722.jpg']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample paths\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape : (136, 136, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a546eabe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a sample image\n",
    "image = ndimage.imread(all_files[0])\n",
    "print('image shape : {0}'.format(image.shape))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to build Nearest Neighbors Model\n",
    "random.shuffle(all_files)\n",
    "num_images = 2000 # increase the number of images to increase the image database\n",
    "neighbor_list = all_files[:num_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty array with shape : num_images * image_embedding_size\n",
    "image_embeddings = np.ndarray((num_images, image_embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n"
     ]
    }
   ],
   "source": [
    "# create image embedding for each image \n",
    "for i, filename in enumerate(neighbor_list):\n",
    "    image = ndimage.imread(filename)\n",
    "    features = sess.run(fc7, feed_dict={x: [image]})\n",
    "    image_embeddings[i:i+1] = features\n",
    "    if i % 250 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of image embeddings\n",
    "image_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Similar Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "NUM_IMAGES = len(neighbor_list)\n",
    "EMBEDDING_DIMENSION = 4096\n",
    "\n",
    "with g.as_default():\n",
    "    # provide input indices \n",
    "    x = tf.placeholder(shape=[None], dtype=tf.int32, name='x')\n",
    "    \n",
    "    # create a constant initializer\n",
    "    weights_initializer = tf.constant_initializer(image_embeddings)\n",
    "    embedding_weights = tf.get_variable(\n",
    "                            name='embedding_weights', \n",
    "                            shape=(NUM_IMAGES, EMBEDDING_DIMENSION), \n",
    "                            initializer=weights_initializer,\n",
    "                            trainable=False)\n",
    "    # emebedding Lookup \n",
    "    embedding_lookup = tf.nn.embedding_lookup(embedding_weights, x)\n",
    "    \n",
    "    # We use the cosine distance:\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embedding_weights), 1, keepdims=True))\n",
    "    normalized_embeddings = embedding_weights / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, x)\n",
    "    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QUERY_IMAGES = 10\n",
    "NUM_NEIGHBORS = 5\n",
    "query_indices = np.random.choice(range(len(neighbor_list)), NUM_QUERY_IMAGES, replace=False)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sim = sess.run(similarity, feed_dict={x : query_indices})\n",
    "    \n",
    "    f,ax = plt.subplots(NUM_QUERY_IMAGES,NUM_NEIGHBORS, sharex=True, sharey=True, figsize=(14,20))\n",
    "    \n",
    "    print('Shape of Similarity Matrix: {0}'.format(sim.shape))\n",
    "    for i,image_index in enumerate(query_indices):\n",
    "       \n",
    "        top_k = NUM_NEIGHBORS # number of nearest neighbors\n",
    "        nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "        log = 'Nearest to {0} :'.format(neighbor_list[image_index])\n",
    "        \n",
    "        for k in range(top_k):\n",
    "            close_image = ndimage.imread(neighbor_list[nearest[k]])\n",
    "            ax[i,k].imshow(close_image)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Extension\n",
    "\n",
    "**Approximate Nearest Neighbor Search** \n",
    "\n",
    "Currently we are comparing each image with every other image that is not recommended for production scenarios. Use techniques such as Approximate Nearest Neighbor to accelerate the process.\n",
    "\n",
    "- You can explore ANNOY  package by Spotify [ https://github.com/spotify/annoy ]\n",
    "- You can also explore LSH ( Locality Senstivity Hashing ) [ https://graphics.stanford.edu/courses/cs468-06-fall/Slides/aneesh-michael.pdf ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
