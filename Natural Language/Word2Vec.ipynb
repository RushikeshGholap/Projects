{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec is a group of models used to transform text data into word-embeddings. Its more useful as compared to using Countvectorizer, TFIDFvectorizer etc as - \n",
    "\n",
    "1. It captures the context of the text and encodes semantics in some form\n",
    "2. It has fixed dimensional (hyperparameter) vectors which helps with computation\n",
    "3. These are usually pre-trained over vast amounts of data and used directly in other models\n",
    "\n",
    "The word vectors created by the models are positioned in the vector space such that the words that share common contexts in the corpus are located closer to each other in the space.\n",
    "\n",
    "The 2 main model architectures in word2vec are - \n",
    "\n",
    "1. CBOW (Continous Bag of words) - Predicts the current word based on the surrounding context words as input\n",
    "2. SG (Skip gram) - Predicts surrounding context words based on current word\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "<u>Training algo</u> - Heirarchial softmax is used when model seeks to maximize conditional log-likelihood and uses Huffman tree. This is better for infrequent words, and lower number of epochs. Negative Sampling is useful when minimizing the log-likelihood of sampled negative instances. Its better for frequent words, lower dimensional vectors and higher number of epochs.\n",
    "\n",
    "<u>Sub-Sampling</u> - Higher freq words have lesser information, this is a threshold to subsample them to increase training speed\n",
    "\n",
    "<u>Dimensionality</u> - Quality of embeddings increases with dimensionality but after a point the marginal gain will diminish.\n",
    "\n",
    "<u>Context window</u> - context window determines how many words before and after the current word will be its context words. Recommended is 10 for SG and 5 for CBOW.\n",
    "\n",
    "\n",
    "<img src='https://lilianweng.github.io/lil-log/assets/images/word2vec-skip-gram.png'></img>\n",
    "\n",
    "**SKIP GRAM ARCHITECURE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2Vec using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1a1e9fdb38>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Online training the model with more sentences\n",
    "model.build_vocab([[\"hello\", \"world\"],['hey','world']], update=True)\n",
    "model.train([[\"hello\", \"world\"],['hey','world']], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9072831e-03, -5.0078036e-04, -1.2205215e-03,  1.7031934e-03,\n",
       "       -8.7878905e-04,  3.2642719e-03,  1.6955030e-03,  1.8635712e-03,\n",
       "        6.0884620e-04,  3.6294644e-03, -5.1687384e-05, -6.7350105e-04,\n",
       "       -1.3855461e-03,  3.8039340e-03, -2.2583394e-03,  2.9560386e-03,\n",
       "       -3.5702975e-03,  2.1870460e-03,  2.5708969e-03,  1.3285197e-03,\n",
       "        1.8306220e-03,  2.4980409e-03, -2.2381789e-03,  4.3474101e-03,\n",
       "       -2.2699737e-03,  2.1978179e-03, -3.5987915e-03, -1.4745519e-03,\n",
       "        8.9427346e-04,  2.5238441e-03, -3.7145237e-03,  2.1708685e-03,\n",
       "       -3.0585675e-04, -1.9012406e-03,  1.7093649e-03,  3.2643725e-03,\n",
       "       -2.7753536e-03,  2.0877942e-03,  8.5415441e-04, -2.3626110e-03,\n",
       "       -1.7397344e-03, -2.4701545e-03, -4.7957557e-03, -2.7853139e-03,\n",
       "        1.9269293e-03,  5.1363495e-05,  2.0468340e-04, -1.8245459e-03,\n",
       "        5.4087868e-04, -3.0424343e-03,  2.0268066e-03,  4.8809272e-04,\n",
       "       -1.6237929e-03,  3.8381990e-03, -4.0810690e-03,  1.5460260e-03,\n",
       "       -4.3985727e-03, -3.5452677e-03, -3.3397174e-03, -1.3920651e-03,\n",
       "        4.9285358e-03,  3.7491261e-03,  1.8839112e-03,  2.0496806e-03,\n",
       "        1.3024154e-03,  2.1044810e-03, -1.1049281e-03,  1.7161814e-03,\n",
       "        2.8153153e-03, -1.4844165e-03, -3.4058554e-04, -2.5665048e-03,\n",
       "        2.7391682e-03,  4.5176051e-03,  1.7721182e-03,  3.2947089e-03,\n",
       "       -1.8655484e-03, -3.9603976e-03, -2.0407976e-03, -4.2551905e-03,\n",
       "        3.6924481e-03, -3.4322285e-03, -1.1118595e-03,  3.4730271e-03,\n",
       "        3.1616904e-03, -4.5024250e-03, -2.7456582e-03, -5.9045036e-04,\n",
       "        4.6392018e-04, -5.7671092e-05,  4.1115852e-03,  2.0864119e-03,\n",
       "       -2.7867905e-03, -3.6722471e-03, -5.2827282e-04, -3.6018330e-03,\n",
       "        1.7772163e-03,  2.3061619e-03,  3.7336501e-03,  1.6083665e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['world']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First download the pre-trained word embeddings\n",
    "#### link - https://github.com/RaRe-Technologies/gensim-data ####\n",
    "\n",
    "#Load pre-trained model\n",
    "model = gensim.models.Word2Vec.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can now be used for creating sentence vectors by taking average (or weighted average with tfidf), or fed into a sequential model to create sequence representations with context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {}\n",
    "settings['n'] = 5                     #Dimensionality of word vectors\n",
    "settings['window_size'] = 2           #Context window\n",
    "settings['min_count'] = 0             #min word count\n",
    "settings['epochs'] = 5000             #training epochs\n",
    "settings['neg_samp'] = 10             #number of negative words to use during training\n",
    "settings['learning_rate'] = 0.01      #learning rate\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have you heard the word the word about the bird', 'hello world word']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['have you heard the word the word about the bird', 'hello world word']\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt = CountVectorizer(stop_words=None)\n",
    "cnt.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(corpus):\n",
    "    X, y = [],[]\n",
    "    training_data = []\n",
    "    for sentence in corpus:\n",
    "        sentence = sentence.split()\n",
    "        len_sent = len(sentence)\n",
    "        \n",
    "        for i in range(len_sent):\n",
    "            \n",
    "            #Get current word\n",
    "            current_word = get_onehot(sentence[i])\n",
    "            \n",
    "            #get context words\n",
    "            context_words = []\n",
    "            for j in range(i-settings['window_size'], i+settings['window_size']+1):\n",
    "                if j!=i and j<=len_sent-1 and j>=0:\n",
    "                    context_words.append(get_onehot(sentence[j]))\n",
    "            X.append(current_word)\n",
    "            y.append(context_words)\n",
    "            training_data.append([current_word, context_words])\n",
    "            \n",
    "    return X, y, training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, training_data = get_training_data(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_count = len(cnt.vocabulary_)\n",
    "v_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array(['have'], dtype='<U5')],\n",
       " [array(['you'], dtype='<U5')],\n",
       " [array(['heard'], dtype='<U5')],\n",
       " [array(['the'], dtype='<U5')],\n",
       " [array(['word'], dtype='<U5')],\n",
       " [array(['the'], dtype='<U5')],\n",
       " [array(['word'], dtype='<U5')],\n",
       " [array(['about'], dtype='<U5')],\n",
       " [array(['the'], dtype='<U5')],\n",
       " [array(['bird'], dtype='<U5')],\n",
       " [array(['hello'], dtype='<U5')],\n",
       " [array(['world'], dtype='<U5')],\n",
       " [array(['word'], dtype='<U5')]]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cnt.inverse_transform(i) for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,y):\n",
    "    w1 = np.random.uniform(-0.8, 0.8, (v_count, n))\n",
    "    w2 = np.random.uniform(-0.8, 0.8, (n, v_count))\n",
    "    \n",
    "    loss=0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        y_pred, h, u = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.uniform(-0.8, 0.8, (v_count, settings['n']))\n",
    "w2 = np.random.uniform(-0.8, 0.8, (settings['n'], v_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x-np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    h = np.dot(w1.T, x)   #(9,5).T DOT (9,) = (5,)\n",
    "    u = np.dot(w2.T, h)   #(5,9).T DOT (5,) = (9,)\n",
    "    y_c = softmax(u)     \n",
    "    return y_c, h, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12512028, 0.19578104, 0.07670136, 0.09175168, 0.08179222,\n",
       "        0.0871506 , 0.08827722, 0.12505659, 0.128369  ]),\n",
       " array([ 0.70999693,  0.29091248, -0.22478736, -0.10074887,  0.31620991]),\n",
       " array([ 0.05641958,  0.50414095, -0.43293657, -0.25377011, -0.36867385,\n",
       "        -0.30521825, -0.29237382,  0.05591038,  0.08205301]))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 5)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.dot(np.array(X), w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 5)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.dot(h, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 9)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c = softmax(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 9)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.subtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5,9) and (13,9) not aligned: 9 (dim 1) != 13 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-e8cf1d3a7be4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-248-4d25850e5799>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (5,9) and (13,9) not aligned: 9 (dim 1) != 13 (dim 0)"
     ]
    }
   ],
   "source": [
    "forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_pred, y_actual):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['heard'], dtype='<U5')]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.inverse_transform(training_data[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array(['have'], dtype='<U5')],\n",
       " [array(['you'], dtype='<U5')],\n",
       " [array(['the'], dtype='<U5')],\n",
       " [array(['word'], dtype='<U5')]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cnt.inverse_transform(i) for i in training_data[2][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'have': 2,\n",
       " 'you': 8,\n",
       " 'heard': 3,\n",
       " 'the': 5,\n",
       " 'word': 6,\n",
       " 'about': 0,\n",
       " 'bird': 1,\n",
       " 'hello': 4,\n",
       " 'world': 7}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = training_data[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = np.sum([np.subtract(pred, word) for word in w_c], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.88173536,  0.69253159,  0.72525428,  0.50132438,  0.95608363,\n",
       "         0.6439902 ,  0.42385505,  0.60639321, -0.9808068 ]),\n",
       " array([ 0.88173536,  0.69253159,  0.72525428, -0.49867562,  0.95608363,\n",
       "         0.6439902 ,  0.42385505,  0.60639321,  0.0191932 ])]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.subtract(pred, i) for i in y[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.76347072,  1.38506318,  1.45050856,  0.00264876,  1.91216727,\n",
       "        1.2879804 ,  0.8477101 ,  1.21278643, -0.9616136 ])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([np.subtract(pred, i) for i in y[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 1]), array([0, 0, 0, 1, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88173536, 0.69253159, 0.72525428, 0.50132438, 0.95608363,\n",
       "       0.6439902 , 0.42385505, 0.60639321, 0.0191932 ])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.random.random((9,))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.19663426,  1.84591745,  2.12211671,  0.4730977 ,  1.55968409,\n",
       "       -0.42658685,  2.77867567])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([pred-i for i in yy], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
