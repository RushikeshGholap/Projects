{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating ORM Facts & Fact Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = ['The Academic with empNr 715 has EmpName ‘Adams A’',\n",
    "        'The Academic with empNr 715 works for the Dept named ‘Computer Science’',\n",
    "        'The Academic with empNr 715 occupies the Room with roomNr ‘69-301’',\n",
    "        'The Academic with empNr 715 uses the Extension with extNr ‘2345’',\n",
    "        'The Extension with extNr ‘2345’ provides the AccessLevel with code ‘LOC’',\n",
    "        'The Academic with empNr 715 is contracted till the Date with mdy-code ‘01/31/95’']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_types =  ['Academic has EmpName',\n",
    "               'Academic works_for Dept',\n",
    "               'Academic occupies Room',\n",
    "               'Academic uses Extension',\n",
    "               'Extension provides AccessLevel',\n",
    "               'Academic is_contracted_till Date',\n",
    "               'Academic is tenured',\n",
    "               'Room contains Academic',\n",
    "               'EmpName belongs_to Academic',\n",
    "               'Dept uses AccessLevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(facts, facts_types), columns=['facts', 'fact_types'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a markov chain & generating facts types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = markovify.NewlineText(fact_types, state_size=1)\n",
    "text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'state_size': 1,\n",
    " 'chain': '[[[\"___BEGIN__\"], {\"Academic\": 6, \"Extension\": 1, \"Room\": 1, \"EmpName\": 1, \"Dept\": 1}], [[\"Academic\"], {\"has\": 1, \"works_for\": 1, \"occupies\": 1, \"uses\": 1, \"is_contracted_till\": 1, \"is\": 1, \"___END__\": 2}], [[\"has\"], {\"EmpName\": 1}], [[\"EmpName\"], {\"___END__\": 1, \"belongs_to\": 1}], [[\"works_for\"], {\"Dept\": 1}], [[\"Dept\"], {\"___END__\": 1, \"uses\": 1}], [[\"occupies\"], {\"Room\": 1}], [[\"Room\"], {\"___END__\": 1, \"contains\": 1}], [[\"uses\"], {\"Extension\": 1, \"AccessLevel\": 1}], [[\"Extension\"], {\"___END__\": 1, \"provides\": 1}], [[\"provides\"], {\"AccessLevel\": 1}], [[\"AccessLevel\"], {\"___END__\": 2}], [[\"is_contracted_till\"], {\"Date\": 1}], [[\"Date\"], {\"___END__\": 1}], [[\"is\"], {\"tenured\": 1}], [[\"tenured\"], {\"___END__\": 1}], [[\"contains\"], {\"Academic\": 1}], [[\"belongs_to\"], {\"Academic\": 1}]]',\n",
    " 'parsed_sentences': [['Academic', 'has', 'EmpName'],\n",
    "  ['Academic', 'works_for', 'Dept'],\n",
    "  ['Academic', 'occupies', 'Room'],\n",
    "  ['Academic', 'uses', 'Extension'],\n",
    "  ['Extension', 'provides', 'AccessLevel'],\n",
    "  ['Academic', 'is_contracted_till', 'Date'],\n",
    "  ['Academic', 'is', 'tenured'],\n",
    "  ['Room', 'contains', 'Academic'],\n",
    "  ['EmpName', 'belongs_to', 'Academic'],\n",
    "  ['Dept', 'uses', 'AccessLevel']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = markovify.NewlineText(fact_types, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.chain = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '[[[\"___BEGIN__\"], {\"Academic\": 6, \"Extension\": 5, \"Room\": 1, \"EmpName\": 1, \"Dept\": 1}], [[\"Academic\"], {\"has\": 1, \"works_for\": 1, \"occupies\": 1, \"uses\": 1, \"is_contracted_till\": 1, \"is\": 1, \"___END__\": 2}], [[\"has\"], {\"EmpName\": 1}], [[\"EmpName\"], {\"___END__\": 1, \"belongs_to\": 1}], [[\"works_for\"], {\"Dept\": 1}], [[\"Dept\"], {\"___END__\": 1, \"uses\": 1}], [[\"occupies\"], {\"Room\": 1}], [[\"Room\"], {\"___END__\": 1, \"contains\": 1}], [[\"uses\"], {\"Extension\": 1, \"AccessLevel\": 1}], [[\"Extension\"], {\"___END__\": 1, \"provides\": 1}], [[\"provides\"], {\"AccessLevel\": 1}], [[\"AccessLevel\"], {\"___END__\": 2}], [[\"is_contracted_till\"], {\"Date\": 1}], [[\"Date\"], {\"___END__\": 1}], [[\"is\"], {\"tenured\": 1}], [[\"tenured\"], {\"___END__\": 1}], [[\"contains\"], {\"Academic\": 1}], [[\"belongs_to\"], {\"Academic\": 1}]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(text_model.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating facts from generated fact type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_fact_type = \"Academic works for Dept uses Extension provides AccessLevel\"\n",
    "generated_fact_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {'Academic':['empNr 715', 'empNr 281', 'empNr 372'],\n",
    "         'Dept':['Sales', 'Marketing', 'Analytics'],\n",
    "         'Extension':['1100', '5502', '3463'],\n",
    "         'AccessLevel':['Read Only', 'Full Access', 'Limited']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacetoken(string):\n",
    "    if string in tokens.keys():\n",
    "        toks = tokens.get(string)\n",
    "        idx = np.random.randint(0,3)\n",
    "        return str(string + ' with ' + toks[idx])\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(' '.join([replacetoken(i) for i in generated_fact_type.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='markovORM.jpg'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The engine first extracts facts from a database or ORM diagram(s)\n",
    "2. Next these facts are turned into fact types and fact tokens are stored separately\n",
    "3. The fact types are used to train a sequential encoder into Thought vectors\n",
    "4. The Thought vectors are then decoded back to generated fact types\n",
    "5. A randomizer then picks up random tokens (some of which are without replacement) and adds them to the generated fact types to generate facts\n",
    "6. These facts are then used to impute a Relational database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Study\n",
    "\n",
    "https://aclweb.org/anthology/P18-1151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Generating ORM facts using input fact types & entity vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import markovify\n",
    "import collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generating fact instances using manual input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take input fact_types\n",
    "def get_input_fact_types(n):\n",
    "    input_fact_types = []\n",
    "    for i in range(n):\n",
    "        print(\"-- Fact #(\",i+1,'/',n,'):')\n",
    "        input_fact_types.append(input())\n",
    "    return input_fact_types\n",
    "\n",
    "\n",
    "#Extracting unique entities based on uppercase\n",
    "def get_unique_enities(fact_types):\n",
    "    entities = []\n",
    "    for i in fact_types:\n",
    "        entities.append([j for j in i.split() if j.isupper()==True])\n",
    "        \n",
    "    unique_entities = list(np.unique([item for sublist in entities for item in sublist]))\n",
    "    return unique_entities\n",
    "\n",
    "#Get vocab for unique entities\n",
    "def get_entity_tokens(input_fact_types):\n",
    "    \n",
    "    unique_entities = get_unique_enities(input_fact_types)\n",
    "    vocab = {}\n",
    "    \n",
    "    for i in unique_entities:\n",
    "        print('-- Entity:',i,'| input examples:')\n",
    "        vocab[i] = [i.strip() for i in input().split(',')]\n",
    "    return vocab\n",
    "\n",
    "\n",
    "#Random sampling with replacement for now\n",
    "def create_instance(unique_vocab):\n",
    "    vocab_instance = {k:np.random.choice(v) for k,v in unique_vocab.items()}\n",
    "    return vocab_instance\n",
    "\n",
    "\n",
    "#Generate fact instances using input_fact_types and vocab\n",
    "def generate_fact_instance(fact_types, unique_vocab):\n",
    "    \n",
    "    vocab_instance = create_instance(unique_vocab)\n",
    "    generated_instance = []\n",
    "    dict_instance = []\n",
    "    \n",
    "    \n",
    "    for fact_type in fact_types:\n",
    "        #generating fact as natural language\n",
    "        words = [str(i+' \\''+vocab_instance.get(i)+'\\'') \n",
    "                 if i in list(vocab_instance.keys()) else i for i in fact_type.split(' ')]\n",
    "        generated_fact = ' '.join(words)\n",
    "        generated_instance.append(generated_fact)\n",
    "        \n",
    "        #generating dict version of the facts\n",
    "        entities = [j for j in fact_type.split() if j.isupper()==True]\n",
    "        dict_entities = {i:vocab_instance.get(i) for i in entities}\n",
    "        dict_instance.append(dict_entities)\n",
    "    \n",
    "    return vocab_instance, generated_instance, dict_instance\n",
    "\n",
    "\n",
    "#Get dictionary instance for each generated fact\n",
    "def generate_n_instances(input_fact_types, vocab, n):\n",
    "    \n",
    "    vi_list = []\n",
    "    fi_list = []\n",
    "    di_list = []\n",
    "    for i in range(n):\n",
    "        vi, fi, di = generate_fact_instance(input_fact_types, vocab)\n",
    "        vi_list.append(vi)\n",
    "        fi_list.append(fi)\n",
    "        di_list.append(di)\n",
    "    \n",
    "    full_vi = vi_list\n",
    "    full_fi = fi_list #np.array(fi_list).T.tolist()\n",
    "    \n",
    "    full_di = []\n",
    "    new_di = np.array(di_list).T.tolist()\n",
    "    for i in new_di:\n",
    "        df = pd.DataFrame.from_dict(i)\n",
    "        dd = df.to_dict(orient='list')\n",
    "        full_di.append(dd)\n",
    "        \n",
    "    return full_vi, full_fi, full_di "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The ACCOUNT_ID is associated with ACCOUNT_TYPE\n",
    "The ACCOUNT_ID is associated with NAME\n",
    "The ACCOUNT_ID is associated with AGE\n",
    "The AGE belongs to CATEGORY\n",
    "The ACCOUNT_TYPE belongs to COUNTRY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fact #( 1 / 5 ):\n",
      "The ACCOUNT_ID is associated with ACCOUNT_TYPE\n",
      "-- Fact #( 2 / 5 ):\n",
      "The ACCOUNT_ID is associated with NAME\n",
      "-- Fact #( 3 / 5 ):\n",
      "The ACCOUNT_ID is associated with AGE\n",
      "-- Fact #( 4 / 5 ):\n",
      "The AGE belongs to CATEGORY\n",
      "-- Fact #( 5 / 5 ):\n",
      "The ACCOUNT_TYPE belongs to COUNTRY\n"
     ]
    }
   ],
   "source": [
    "#STEP 1: Input fact types\n",
    "input_fact_types = get_input_fact_types(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The ACCOUNT_ID is associated with ACCOUNT_TYPE',\n",
       " 'The ACCOUNT_ID is associated with NAME',\n",
       " 'The ACCOUNT_ID is associated with AGE',\n",
       " 'The AGE belongs to CATEGORY',\n",
       " 'The ACCOUNT_TYPE belongs to COUNTRY']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fact_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Entity: ACCOUNT_ID | input examples:\n",
      "1111,2222,3333,4444,5555,6666,7777,8888\n",
      "-- Entity: ACCOUNT_TYPE | input examples:\n",
      "Primary, Secondary\n",
      "-- Entity: AGE | input examples:\n",
      "20,21,22,23,24,25,26,27,28,29,30\n",
      "-- Entity: CATEGORY | input examples:\n",
      "Junior,Senior, Super Senior\n",
      "-- Entity: COUNTRY | input examples:\n",
      "India, US, UK, Germany\n",
      "-- Entity: NAME | input examples:\n",
      "Bill, Akshay, Sumit, Paritosh\n"
     ]
    }
   ],
   "source": [
    "#STEP 2: Input example tokens for fact type entities\n",
    "vocab = get_entity_tokens(input_fact_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACCOUNT_ID': ['1111', '2222', '3333', '4444', '5555', '6666', '7777', '8888'],\n",
      " 'ACCOUNT_TYPE': ['Primary', 'Secondary'],\n",
      " 'AGE': ['20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30'],\n",
      " 'CATEGORY': ['Junior', 'Senior', 'Super Senior'],\n",
      " 'COUNTRY': ['India', 'US', 'UK', 'Germany'],\n",
      " 'NAME': ['Bill', 'Akshay', 'Sumit', 'Paritosh']}\n"
     ]
    }
   ],
   "source": [
    "pprint(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#STEP 3: Generate n fact instances from the fact types and vocab\n",
    "vi, fi, di = generate_n_instances(input_fact_types, vocab, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACCOUNT_ID': '1111',\n",
       " 'ACCOUNT_TYPE': 'Secondary',\n",
       " 'AGE': '22',\n",
       " 'CATEGORY': 'Senior',\n",
       " 'COUNTRY': 'US',\n",
       " 'NAME': 'Sumit'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"The ACCOUNT_ID '1111' is associated with ACCOUNT_TYPE 'Secondary'\",\n",
       "  \"The ACCOUNT_ID '1111' is associated with NAME 'Sumit'\",\n",
       "  \"The ACCOUNT_ID '1111' is associated with AGE '22'\",\n",
       "  \"The AGE '22' belongs to CATEGORY 'Senior'\",\n",
       "  \"The ACCOUNT_TYPE 'Secondary' belongs to COUNTRY 'US'\"],\n",
       " [\"The ACCOUNT_ID '2222' is associated with ACCOUNT_TYPE 'Secondary'\",\n",
       "  \"The ACCOUNT_ID '2222' is associated with NAME 'Paritosh'\",\n",
       "  \"The ACCOUNT_ID '2222' is associated with AGE '21'\",\n",
       "  \"The AGE '21' belongs to CATEGORY 'Senior'\",\n",
       "  \"The ACCOUNT_TYPE 'Secondary' belongs to COUNTRY 'UK'\"],\n",
       " [\"The ACCOUNT_ID '5555' is associated with ACCOUNT_TYPE 'Primary'\",\n",
       "  \"The ACCOUNT_ID '5555' is associated with NAME 'Akshay'\",\n",
       "  \"The ACCOUNT_ID '5555' is associated with AGE '30'\",\n",
       "  \"The AGE '30' belongs to CATEGORY 'Junior'\",\n",
       "  \"The ACCOUNT_TYPE 'Primary' belongs to COUNTRY 'India'\"],\n",
       " [\"The ACCOUNT_ID '8888' is associated with ACCOUNT_TYPE 'Primary'\",\n",
       "  \"The ACCOUNT_ID '8888' is associated with NAME 'Paritosh'\",\n",
       "  \"The ACCOUNT_ID '8888' is associated with AGE '22'\",\n",
       "  \"The AGE '22' belongs to CATEGORY 'Super Senior'\",\n",
       "  \"The ACCOUNT_TYPE 'Primary' belongs to COUNTRY 'Germany'\"],\n",
       " [\"The ACCOUNT_ID '6666' is associated with ACCOUNT_TYPE 'Primary'\",\n",
       "  \"The ACCOUNT_ID '6666' is associated with NAME 'Bill'\",\n",
       "  \"The ACCOUNT_ID '6666' is associated with AGE '24'\",\n",
       "  \"The AGE '24' belongs to CATEGORY 'Junior'\",\n",
       "  \"The ACCOUNT_TYPE 'Primary' belongs to COUNTRY 'UK'\"]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ACCOUNT_ID': ['1111', '2222', '5555', '8888', '6666'],\n",
       "  'ACCOUNT_TYPE': ['Secondary', 'Secondary', 'Primary', 'Primary', 'Primary']},\n",
       " {'ACCOUNT_ID': ['1111', '2222', '5555', '8888', '6666'],\n",
       "  'NAME': ['Sumit', 'Paritosh', 'Akshay', 'Paritosh', 'Bill']},\n",
       " {'ACCOUNT_ID': ['1111', '2222', '5555', '8888', '6666'],\n",
       "  'AGE': ['22', '21', '30', '22', '24']},\n",
       " {'AGE': ['22', '21', '30', '22', '24'],\n",
       "  'CATEGORY': ['Senior', 'Senior', 'Junior', 'Super Senior', 'Junior']},\n",
       " {'ACCOUNT_TYPE': ['Secondary', 'Secondary', 'Primary', 'Primary', 'Primary'],\n",
       "  'COUNTRY': ['US', 'UK', 'India', 'Germany', 'UK']}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNT_ID</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111</td>\n",
       "      <td>Sumit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222</td>\n",
       "      <td>Paritosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5555</td>\n",
       "      <td>Akshay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8888</td>\n",
       "      <td>Paritosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6666</td>\n",
       "      <td>Bill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ACCOUNT_ID      NAME\n",
       "0       1111     Sumit\n",
       "1       2222  Paritosh\n",
       "2       5555    Akshay\n",
       "3       8888  Paritosh\n",
       "4       6666      Bill"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(di[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Example from the first model shared as examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a model, as shared as example\n",
    "\n",
    "bill_facts_1 = [\"The PARTY with PARTY_ID 'P0001' exists .\",\n",
    "\"The ACCOUNT with ACCOUNT_ID 'AC001' exists .\",\n",
    "\"The TRADER with USER_ID 'TR-001' exists .\",\n",
    "\"The ORDER with ORDER_ID 'O0001' exists .\",\n",
    "\"The ACCOUNT with ACCOUNT_NO 'A9-001' exists .\",\n",
    "\"The INSTRUCTION with INSTRUCTION_ID 'I0001' exists .\",\n",
    "\"The USER with USER_ID 'U0001' exists .\",\n",
    "\"The ALLOCATION with ALLOC_ID 'A0001' exists .\",\n",
    "\"The EXECUTION with EXEC_ID 'X0001' exists .\",\n",
    "\"The QUOTE with QUOTE_ID 'Q0001' exists .\",\n",
    "\"The BUSINESS_GROUP with GROUP_ID'BG1' exists.\",\n",
    "\"The TRADE with TRADE_ID 'TX-0001' exists.\",\n",
    "\"The BUSINESS_GROUP 'BG1' has NAME 'House Traders' .\",\n",
    "\"The BUSINESS_GROUP 'BG2' has NAME 'Floor Traders' .\",\n",
    "\"The BUSINESS_GROUP 'BG1' has member USER 'U0001' .\",\n",
    "\"The BUSINESS_GROUP 'BG2' has member TRADER 'TR-001' .\",\n",
    "\"The TRADER 'TR-001' issued ORDER 'O0001' .\",\n",
    "\"The PARTY 'P0001' requested QUOTE 'Q0001' .\",\n",
    "\"The ORDER 'O0001' was issued for QUOTE 'Q0001' .\",\n",
    "\"The ORDER 'O0001' was executed on TRADE-DATE '06-27-2018' .\",\n",
    "\"The ORDER 'O0001' has BASE_CURR_CD 'USD' .\",\n",
    "\"The ORDER 'O0001' has QUOTE_CURR_CD 'USD' .\",\n",
    "\"The ORDER 'O0001' has TRADE_SIDE_CD '1' .\",\n",
    "\"The ORDER 'O0001' has ORDER_QTY '9' .\",\n",
    "\"The ORDER 'O0001' has SPOT_RATE '89.08' .\",\n",
    "\"The ORDER 'O0001' has FORWARD_RATE '87.12' .\",\n",
    "\"The ORDER 'O0001' has FORWARD_DATE '06-27-2018' .\",\n",
    "\"The ORDER 'O0001' has VALUE_DATE '06-27-2018' .\",\n",
    "\"The ORDER 'O0001' has FORWARD_TYPE_CD '7' .\",\n",
    "\"The ORDER 'O0001' has LOWER_BND_LIM '80.00' .\",\n",
    "\"The ORDER 'O0001' has UPPER_BND_LIM '100.00' .\",\n",
    "\"The ORDER 'O0001' issued by TRADER 'TR-001' .\",\n",
    "\"The ORDER 'O0001' has GOOD_TYPE '7' .\",\n",
    "\"The ORDER 'O0001' has GOOD_DATE '06-30-2018' .\",\n",
    "\"The ORDER 'O0001' has ACCEPTED_TS '2019-06-27 09:12:15' .\",\n",
    "\"The ORDER 'O0001' has ACK_TS '2019-06-27 09:13:00' .\",\n",
    "\"The ORDER 'O0001' has COMPLIANCE_GRP_ID '1' .\",\n",
    "\"The ORDER 'O0001' has HIST_FLAG '1' .\",\n",
    "\"The ORDER 'O0001' has ADDED_TS '2019-06-27 10:15:18' .\",\n",
    "\"The ORDER 'O0001' has ADDED_BY 'U0001' .\",\n",
    "\"The ORDER 'O0001' has UPDT_TS '' .\",\n",
    "\"The ORDER 'O0001' has UPDT_BY '' .\",\n",
    "\"The ORDER 'O0001' has VERSION '1' .\",\n",
    "\"The QUOTE 'Q0001' has QUOTE_TYPE_CD '1' .\",\n",
    "\"The QUOTE_TYPE_CD '1' has QUOTE_TYPE_DESC 'INDICATIVE'.\",\n",
    "\"The QUOTE_TYPE_CD '2' has QUOTE_TYPE_DESC 'TRADEABLE'.\",\n",
    "\"The QUOTE_TYPE_CD '3' has QUOTE_TYPE_DESC 'RESTRICTED_TRADEABLE'.\",\n",
    "\"The QUOTE_TYPE_CD '4' has QUOTE_TYPE_DESC 'COUNTER_TRADEABLE'.\",\n",
    "\"The EXECUTION_ALLOCATION with EXEC_ALLOC_ID 'EA0001' exists .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' was executed on TRADE-DATE '06-27-2018' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has EXEC_ID 'X0001' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has ALLOC_ID 'A0001' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has OUTSTANDING_QTY '0' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has ALLOCATED_QTY '100' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has ALLOC_TS '2018-01-19 03:14:07' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has HIST_FLAG '1' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has ADDED_TS '2018-01-19 03:15:18' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has ADDED_BY 'U0001' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has UPDT_TS '' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has UPDT_BY '' .\",\n",
    "\"The EXECUTION_ALLOCATION 'EA0001' has VERSION '1' .\",\n",
    "\"The ALLOCATION 'A0001' has SETTLEMENT_CD '1' .\",\n",
    "\"The SETTLEMENT_CD '1' has SETTLEMENT_TYPE_DESC 'REGULAR' .\",\n",
    "\"The SETTLEMENT_CD '2' has SETTLEMENT_TYPE_DESC 'CASH' .\",\n",
    "\"The SETTLEMENT_CD '3' has SETTLEMENT_TYPE_DESC 'NEXT_DAY' .\",\n",
    "\"The SETTLEMENT_CD '4' has SETTLEMENT_TYPE_DESC 'T+2' .\",\n",
    "\"The SETTLEMENT_CD '5' has SETTLEMENT_TYPE_DESC 'T+3' .\",\n",
    "\"The SETTLEMENT_CD '6' has SETTLEMENT_TYPE_DESC 'T+4' .\",\n",
    "\"The SETTLEMENT_CD '7' has SETTLEMENT_TYPE_DESC 'T+5' .\",\n",
    "\"The SETTLEMENT_CD '8' has SETTLEMENT_TYPE_DESC 'FUTURE' .\",\n",
    "\"The SETTLEMENT_CD '9' has SETTLEMENT_TYPE_DESC 'WHEN_AND_IF_ISSUED' .\",\n",
    "\"The SETTLEMENT_CD '10' has SETTLEMENT_TYPE_DESC 'SELLERS_OPTION' .\",\n",
    "\"The ACCOUNT 'AC001' has ACCOUNT_TYPE_CD '1' .\",\n",
    "\"The ACCOUNT_TYPE_CD '1' has ACCOUNT_TYPE_DESC 'Account is carried on customer side of Books' .\",\n",
    "\"The ACCOUNT_TYPE_CD '2' has ACCOUNT_TYPE_DESC 'Account is carried on non-customer side of Books' .\",\n",
    "\"The ACCOUNT_TYPE_CD '3' has ACCOUNT_TYPE_DESC 'House Trader' .\",\n",
    "\"The ACCOUNT_TYPE_CD '4' has ACCOUNT_TYPE_DESC 'Floor Trader' .\",\n",
    "\"The ACCOUNT_TYPE_CD '5' has ACCOUNT_TYPE_DESC 'Account is carried on non-customer side of books and is cross margined' .\",\n",
    "\"The ACCOUNT_TYPE_CD '6' has ACCOUNT_TYPE_DESC 'Account is house trader and is cross margined' .\",\n",
    "\"The ACCOUNT_TYPE_CD '7' has ACCOUNT_TYPE_DESC 'Joint Backoffice Account (JBO)' .\",\n",
    "\"The TRADE 'TX-0001' has COMMISSION_TYPE_CD '1' .\",\n",
    "\"The COMMISSION_TYPE_CD '1' has COMMISSION_TYPE_DESC 'per unit' .\",\n",
    "\"The COMMISSION_TYPE_CD '2' has COMMISSION_TYPE_DESC 'percentage' .\",\n",
    "\"The COMMISSION_TYPE_CD '3' has COMMISSION_TYPE_DESC 'absolute (total monetary amount)' .\",\n",
    "\"The COMMISSION_TYPE_CD '4' has COMMISSION_TYPE_DESC 'percentage waived - cash discount' .\",\n",
    "\"The COMMISSION_TYPE_CD '5' has COMMISSION_TYPE_DESC 'percentage waived - enhanced units' .\",\n",
    "\"The COMMISSION_TYPE_CD '6' has COMMISSION_TYPE_DESC 'points per bond or or contract' .\",\n",
    "\"The TRADE 'TX-0001' has TRADE_TYPE_CD '0' .\",\n",
    "\"The TRADE_TYPE_CD '0' has TRADE_TYPE_DESC 'Regular Trade' .\",\n",
    "\"The TRADE_TYPE_CD '1' has TRADE_TYPE_DESC 'Block Trade' .\",\n",
    "\"The TRADE_TYPE_CD '2' has TRADE_TYPE_DESC 'Exchange for Physical (EFP)' .\",\n",
    "\"The TRADE_TYPE_CD '3' has TRADE_TYPE_DESC 'Transfer' .\",\n",
    "\"The TRADE_TYPE_CD '4' has TRADE_TYPE_DESC 'Late Trade' .\",\n",
    "\"The TRADE_TYPE_CD '5' has TRADE_TYPE_DESC 'T Trade' .\",\n",
    "\"The TRADE_TYPE_CD '6' has TRADE_TYPE_DESC 'Weighted Average Price Trade' .\",\n",
    "\"The TRADE_TYPE_CD '7' has TRADE_TYPE_DESC 'Bunched Trade' .\",\n",
    "\"The TRADE_TYPE_CD '8' has TRADE_TYPE_DESC 'Late Bunched Trade' .\",\n",
    "\"The TRADE_TYPE_CD '9' has TRADE_TYPE_DESC 'Prior Reference Price Trade' .\",\n",
    "\"The TRADE_TYPE_CD '10' has TRADE_TYPE_DESC 'After Hours Trade' .\",\n",
    "\"The TRADE 'TX-0001' has INSTRUCTION 'I0001' .\",\n",
    "\"The INSTRUCTION 'I0001' has INSTRUCTION_TYPE_CD '1' .\",\n",
    "\"The INSTRUCTION_TYPE_CD '1' has INSTRUCTION_TYPE_DESC 'Calculated (includes MiscFees and NetMoney)'.\",\n",
    "\"The INSTRUCTION_TYPE_CD '2' has INSTRUCTION_TYPE_DESC 'Preliminary (without MiscFees and NetMoney)'.\",\n",
    "\"The INSTRUCTION_TYPE_CD '3' has INSTRUCTION_TYPE_DESC 'Sellside Calculated Using Preliminary'.\",\n",
    "\"The INSTRUCTION_TYPE_CD '4' has INSTRUCTION_TYPE_DESC 'Sellside Calculated Without Preliminary'.\",\n",
    "\"The INSTRUCTION_TYPE_CD '5' has INSTRUCTION_TYPE_DESC 'Ready-To-Book - Single Order'.\",\n",
    "\"The INSTRUCTION_TYPE_CD '6' has INSTRUCTION_TYPE_DESC 'Buyside Ready-To-Book - Combined Set of Orders (Replaced)'.\",\n",
    "\"The INSTRUCTION_TYPE_CD '7' has INSTRUCTION_TYPE_DESC 'Warehouse instruction'.\",\n",
    "\"The INSTRUCTION_TYPE_CD '8' has INSTRUCTION_TYPE_DESC 'Request to Intermediary'.\",\n",
    "\"The TRADE 'TX-0001' has EVENT_TYPE_CD '1' .\",\n",
    "\"The EVENT_TYPE_CD '1' has EVENT_TYPE_DESC 'PUT'.\",\n",
    "\"The EVENT_TYPE_CD '2' has EVENT_TYPE_DESC 'CALL'.\",\n",
    "\"The EVENT_TYPE_CD '3' has EVENT_TYPE_DESC 'TENDER'.\",\n",
    "\"The EVENT_TYPE_CD '4' has EVENT_TYPE_DESC 'SINKING FUND CALL'.\",\n",
    "\"The EVENT_TYPE_CD '99' has EVENT_TYPE_DESC 'OTHER'.\",\n",
    "\"The TRADE 'TX-0001' involves COUNTER_PARTY 'P0001' having PARTY_ROLE 'BUYER' .\",\n",
    "\"The TRADE 'TX-0001' involves COUNTER_PARTY 'P0002' having PARTY_ROLE 'SELLER' .\",\n",
    "\"The TRADE 'TX-0001' was executed by TRADER 'TR-001' .\",\n",
    "\"The PARTY 'P0001' has PARTY_TYPE 'ORGANIZATION' .\",\n",
    "\"The PARTY 'P0001' has PARTY_NAME 'Acme Paper Group' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'HEADQUARTERS_COUNTRY' with PARTY_CHARACTERISTIC_VALUE 'US' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'HEADQUARTERS_STREET_NAME' with PARTY_CHARACTERISTIC_VALUE 'Turnpike Drive' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'HEADQUARTERS_STREET_NUMBER' with PARTY_CHARACTERISTIC_VALUE '2700' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'HEADQUARTERS_CITY' with PARTY_CHARACTERISTIC_VALUE 'Hatboro' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'HEADQUARTERS_POSTAL_CODE' with PARTY_CHARACTERISTIC_VALUE '19040' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'LEGAL_ENTITY_ID' with PARTY_CHARACTERISTIC_VALUE '549300JPOPI49S3LIQ04' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'LEGAL_NAME' with PARTY_CHARACTERISTIC_VALUE 'Acme Corrugated Box Co., Inc.' .\",\n",
    "\"The PARTY 'P0001' has PARTY_CHARACTERISTIC_TYPE 'LEGAL_FORM_CODE' with PARTY_CHARACTERISTIC_VALUE '9999 - CORPORATION' .\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the input needed is fact_types and vocab for entities, \n",
    "#the following functions reverse engineer the required inputs from given fact examples\n",
    "\n",
    "def extract_fact_type(s):\n",
    "    parts = s.split('\\'')\n",
    "    fact_type0 = ' '.join([parts[i].strip() for i in range(len(parts)) if i%2==0])\n",
    "    fact_type1 = fact_type0.replace('.','').strip()\n",
    "    return fact_type1\n",
    "\n",
    "def get_facts(facts_model):\n",
    "    fact_types = list(np.unique([extract_fact_type(i) for i in facts_model]))\n",
    "    return fact_types\n",
    "\n",
    "def extract_entity_token_tuple(s):\n",
    "    parts = s.split('\\'')\n",
    "    fact_tokens = [[parts[i].strip()] for i in range(len(parts)) if i%2!=0]\n",
    "    \n",
    "    remaining_fact = ' || '.join([parts[i].strip() for i in range(len(parts)) if i%2==0])\n",
    "    \n",
    "    words = remaining_fact.split(' ')\n",
    "    ett = [words[i-1] for i in range(len(words)) if words[i]=='||']\n",
    "    \n",
    "    return list(zip(ett, fact_tokens))\n",
    "\n",
    "def extract_entity_token_vocab(facts_model):\n",
    "    tuples = [extract_entity_token_tuple(i) for i in facts_model]\n",
    "    tuples_flat = [item for sublist in tuples for item in sublist]\n",
    "    \n",
    "    c = collections.defaultdict(list)\n",
    "    for a,b in tuples_flat:\n",
    "        c[a].extend(b)  # add to existing list or create a new one\n",
    "\n",
    "    vocab = dict(c.items())\n",
    "    unique_vocab = {k:list(np.unique(v)) for k,v in vocab.items()}\n",
    "    \n",
    "    return unique_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fact_types = get_facts(bill_facts_1)\n",
    "vocab = extract_entity_token_vocab(bill_facts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi, fi, di = generate_n_instances(input_fact_types, vocab, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PARTY_ID': 'P0001',\n",
       " 'ACCOUNT_ID': 'AC001',\n",
       " 'USER_ID': 'TR-001',\n",
       " 'ORDER_ID': 'O0001',\n",
       " 'ACCOUNT_NO': 'A9-001',\n",
       " 'INSTRUCTION_ID': 'I0001',\n",
       " 'ALLOC_ID': 'A0001',\n",
       " 'EXEC_ID': 'X0001',\n",
       " 'QUOTE_ID': 'Q0001',\n",
       " 'GROUP_ID': 'BG1',\n",
       " 'TRADE_ID': 'TX-0001',\n",
       " 'BUSINESS_GROUP': 'BG1',\n",
       " 'NAME': 'Floor Traders',\n",
       " 'USER': 'U0001',\n",
       " 'TRADER': 'TR-001',\n",
       " 'ORDER': 'O0001',\n",
       " 'PARTY': 'P0001',\n",
       " 'QUOTE': 'Q0001',\n",
       " 'TRADE-DATE': '06-27-2018',\n",
       " 'BASE_CURR_CD': 'USD',\n",
       " 'QUOTE_CURR_CD': 'USD',\n",
       " 'TRADE_SIDE_CD': '1',\n",
       " 'ORDER_QTY': '9',\n",
       " 'SPOT_RATE': '89.08',\n",
       " 'FORWARD_RATE': '87.12',\n",
       " 'FORWARD_DATE': '06-27-2018',\n",
       " 'VALUE_DATE': '06-27-2018',\n",
       " 'FORWARD_TYPE_CD': '7',\n",
       " 'LOWER_BND_LIM': '80.00',\n",
       " 'UPPER_BND_LIM': '100.00',\n",
       " 'GOOD_TYPE': '7',\n",
       " 'GOOD_DATE': '06-30-2018',\n",
       " 'ACCEPTED_TS': '2019-06-27 09:12:15',\n",
       " 'ACK_TS': '2019-06-27 09:13:00',\n",
       " 'COMPLIANCE_GRP_ID': '1',\n",
       " 'HIST_FLAG': '1',\n",
       " 'ADDED_TS': '2019-06-27 10:15:18',\n",
       " 'ADDED_BY': 'U0001',\n",
       " 'UPDT_TS': '',\n",
       " 'UPDT_BY': '',\n",
       " 'VERSION': '1',\n",
       " 'QUOTE_TYPE_CD': '3',\n",
       " 'QUOTE_TYPE_DESC': 'COUNTER_TRADEABLE',\n",
       " 'EXEC_ALLOC_ID': 'EA0001',\n",
       " 'EXECUTION_ALLOCATION': 'EA0001',\n",
       " 'OUTSTANDING_QTY': '0',\n",
       " 'ALLOCATED_QTY': '100',\n",
       " 'ALLOC_TS': '2018-01-19 03:14:07',\n",
       " 'ALLOCATION': 'A0001',\n",
       " 'SETTLEMENT_CD': '7',\n",
       " 'SETTLEMENT_TYPE_DESC': 'NEXT_DAY',\n",
       " 'ACCOUNT': 'AC001',\n",
       " 'ACCOUNT_TYPE_CD': '6',\n",
       " 'ACCOUNT_TYPE_DESC': 'Account is carried on customer side of Books',\n",
       " 'TRADE': 'TX-0001',\n",
       " 'COMMISSION_TYPE_CD': '6',\n",
       " 'COMMISSION_TYPE_DESC': 'percentage waived - cash discount',\n",
       " 'TRADE_TYPE_CD': '8',\n",
       " 'TRADE_TYPE_DESC': 'T Trade',\n",
       " 'INSTRUCTION': 'I0001',\n",
       " 'INSTRUCTION_TYPE_CD': '6',\n",
       " 'INSTRUCTION_TYPE_DESC': 'Request to Intermediary',\n",
       " 'EVENT_TYPE_CD': '1',\n",
       " 'EVENT_TYPE_DESC': 'PUT',\n",
       " 'COUNTER_PARTY': 'P0001',\n",
       " 'PARTY_ROLE': 'SELLER',\n",
       " 'PARTY_TYPE': 'ORGANIZATION',\n",
       " 'PARTY_NAME': 'Acme Paper Group',\n",
       " 'PARTY_CHARACTERISTIC_TYPE': 'HEADQUARTERS_STREET_NAME',\n",
       " 'PARTY_CHARACTERISTIC_VALUE': 'US'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNT_TYPE_CD</th>\n",
       "      <th>ACCOUNT_TYPE_DESC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Account is carried on customer side of Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Floor Trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>House Trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Joint Backoffice Account (JBO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>House Trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Account is carried on non-customer side of boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Floor Trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Account is carried on non-customer side of Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Floor Trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Account is carried on non-customer side of Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Account is carried on non-customer side of Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Account is carried on customer side of Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>Account is carried on non-customer side of boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Account is carried on non-customer side of boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Floor Trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>House Trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>Account is carried on non-customer side of Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Account is carried on customer side of Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>Account is house trader and is cross margined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>Account is house trader and is cross margined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACCOUNT_TYPE_CD                                  ACCOUNT_TYPE_DESC\n",
       "0                6       Account is carried on customer side of Books\n",
       "1                4                                       Floor Trader\n",
       "2                2                                       House Trader\n",
       "3                3                     Joint Backoffice Account (JBO)\n",
       "4                4                                       House Trader\n",
       "5                4  Account is carried on non-customer side of boo...\n",
       "6                4                                       Floor Trader\n",
       "7                7   Account is carried on non-customer side of Books\n",
       "8                4                                       Floor Trader\n",
       "9                1   Account is carried on non-customer side of Books\n",
       "10               2   Account is carried on non-customer side of Books\n",
       "11               6       Account is carried on customer side of Books\n",
       "12               7  Account is carried on non-customer side of boo...\n",
       "13               3  Account is carried on non-customer side of boo...\n",
       "14               1                                       Floor Trader\n",
       "15               5                                       House Trader\n",
       "16               3   Account is carried on non-customer side of Books\n",
       "17               1       Account is carried on customer side of Books\n",
       "18               6      Account is house trader and is cross margined\n",
       "19               1      Account is house trader and is cross margined"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(di[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary - \n",
    "\n",
    "Please refer to - \n",
    "- the input_fact_types and vocab variables for inputs\n",
    "- the vi, fi, di variables for the expected outputs\n",
    "\n",
    "Implemented - \n",
    "1. A series of fact types can be seen as a graph of connected entities.\n",
    "1. Given a graph of fact types and a backend entity vocabulary, its possible to generate instances of said graph by sampling from the entity vocabulary\n",
    "3. Then these instances can be reorganised as tables to be dumped into a database\n",
    "\n",
    "Work needed on - \n",
    "1. The method of generating examples for an entity need to be created using libraries such as FAKER\n",
    "2. Currently, random sampling is being used for creating instances of the graph. This strategy needs to be modified so as to ensure that certain parameters act as unique identifiers for the graph (meaning they occur only once, and must pe popped from the queue once used to generate an instance), while others are random choice and can repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
