{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "output_notebook()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1 (Blue mask + blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "output_notebook()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA) # because Bokeh expects a RGBA image\n",
    "frame=cv2.flip(frame, -1) # because Bokeh flips vertically\n",
    "width=frame.shape[1]\n",
    "height=frame.shape[0]\n",
    "p = figure(x_range=(0,width), y_range=(0,height), output_backend=\"webgl\", width=width, height=height)\n",
    "myImage = p.image_rgba(image=[frame], x=0, y=0, dw=width, dh=height)\n",
    "show(p, notebook_handle=True)\n",
    "\n",
    "low_hsv = np.array([95,100,10])\n",
    "high_hsv = np.array([135,255,255])\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #Transformation\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, low_hsv, high_hsv)\n",
    "    roi = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    frame = cv2.blur(roi,(3,3))\n",
    "    ##End\n",
    "    \n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    frame=cv2.flip(frame, -1)\n",
    "    myImage.data_source.data['image']=[frame]\n",
    "    push_notebook()\n",
    "    time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 (Face detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script will detect faces via your webcam.\n",
    "# Tested with OpenCV3\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "        #flags = cv2.CV_HAAR_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    #print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 3 (scikit-image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_img = rgb2hsv(original)\n",
    "hue_img = hsv_img[:,:,0]\n",
    "value_img = hsv_img[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hue_img, cmap='hsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(value_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_threshold = 0.06\n",
    "binary_img = hue_img > hue_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize = (10,5))\n",
    "ax0.hist(hue_img.ravel(),512)\n",
    "ax0.axvline(x=hue_threshold, color='r', linestyle='dashed')\n",
    "ax1.imshow(binary_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_threshold = 0.1\n",
    "binary_img = (hue_img > hue_threshold) | (value_img < value_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(binary_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hed\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_hema = LinearSegmentedColormap.from_list('mycmap',['white', 'navy'])\n",
    "cmap_dab = LinearSegmentedColormap.from_list('mycmap',['white', 'saddlebrown'])\n",
    "cmap_eos = LinearSegmentedColormap.from_list('mycmap',['darkviolet', 'white'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihc_rgb = data.immunohistochemistry()\n",
    "plt.imshow(ihc_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihc_hed = rgb2hed(ihc_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize = (15,5))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(ihc_hed[:,:,0], cmap=cmap_hema)\n",
    "ax[1].imshow(ihc_hed[:,:,1], cmap=cmap_dab)\n",
    "ax[2].imshow(ihc_hed[:,:,2], cmap=cmap_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "h = rescale_intensity(ihc_hed[:,:,0], out_range=(0,1))\n",
    "d = rescale_intensity(ihc_hed[:,:,1], out_range=(0,1))\n",
    "\n",
    "zdh = np.dstack((np.zeros_like(h), d, h))\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize=(15,5))\n",
    "axes.imshow(zdh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
